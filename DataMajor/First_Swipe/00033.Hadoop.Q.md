# Mock Interview â€” Hadoop (HDFS / MapReduce)

Same rules â€” answer in the room, model answer and diagrams after each response.

---

## Question 1 â€” Warming Up (The "Single Point of Failure" Check)

**"Hadoop is designed to be fault-tolerant. If I lose a DataNode, nothing happens. But what happens if I lose the NameNode? Why is that architecture considered a risk?"**

# Feedback First

## What You Nailed âœ…
*   **The Brain:** Correctly identified the NameNode as the "Brain" or "Phonebook" of the cluster.
*   **Split Brain:** Mentioned that without the NameNode, the cluster is useless because clients don't know where the blocks are. "I have the data, but I can't find it."
*   **Secondary NameNode:** Mentioned the Secondary NameNode (though often misunderstood as a hot standby, it's actually a checkpoint helper).

## What to Tighten Up ğŸ”§
*   **High Availability (HA):** In modern Hadoop (Hadoop 2+), we use **Zookeeper** to manage an Active/Standby NameNode pair. If the Active dies, the Standby takes over instantly.
*   **Edit Logs:** Explain that the NameNode writes changes to an `EditLog`. If that log is corrupted, the filesystem is dead.

# Model Answer

---

"The NameNode is the **Single Point of Failure (SPOF)** in older Hadoop architectures.

**Why:**
The NameNode holds the entire filesystem metadata (file-to-block mapping) in **RAM**. If the NameNode crashes, the RAM is wiped.
Even though the DataNodes still have the blocks on their hard drives, the cluster has 'Amnesia'. It doesn't know which block belongs to which file. The data is effectively lost.

**Mitigation (Modern HA):**
In production, we run an **Active/Standby** pair managed by Zookeeper.
1.  **Active:** Handles all client requests.
2.  **Standby:** Constantly reads the `EditLog` from the JournalNodes to stay in sync.
3.  **Failover:** If Active dies, Zookeeper promotes Standby to Active instantly."

# Diagrams

```text
NAMENODE HIGH AVAILABILITY (HA)
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  CLIENT (User)                                                        â•‘
â•‘      â”‚                                                                â•‘
â•‘      â–¼                                                                â•‘
â•‘  [ ZOOKEEPER ] (The Referee)                                          â•‘
â•‘      â”‚                                                                â•‘
â•‘      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                     â•‘
â•‘      â–¼                          â–¼                                     â•‘
â•‘  NAMENODE 1 (__Active__)    NAMENODE 2 (Standby)                      â•‘
â•‘  [RAM: Metadata]            [RAM: Metadata]                           â•‘
â•‘      â”‚                          â–²                                     â•‘
â•‘      â”‚ Writes Logs              â”‚ Reads Logs                          â•‘
â•‘      â–¼                          â”‚                                     â•‘
â•‘  [ JOURNAL NODES (Shared Storage) ]                                   â•‘
â•‘                                                                       â•‘
â•‘  "If NameNode 1 dies, Zookeeper tells NameNode 2 to wake up."         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## Question 2 â€” Data Engineer Level (The "Block Size" Check)

**"In Linux, the standard block size is 4KB. In HDFS, the default is 128MB. Why is HDFS configured with such a massive block size? What is the trade-off?"**

# Feedback First

## What You Nailed âœ…
*   **Seek Time vs Transfer Time:** Correctly identified that moving the disk head (Seek) is slow (10ms), while reading data (Transfer) is fast (100MB/s).
*   **Streaming:** Mentioned that Hadoop is for big scans, not small random reads.

## What to Tighten Up ğŸ”§
*   **Metadata Overhead:** This is crucial. Every block requires metadata in the NameNode's RAM (about 150 bytes per block).
    *   *Scenario A:* 1PB of data with 4KB blocks = Trillions of objects. **NameNode crashes (OOM).**
    *   *Scenario B:* 1PB of data with 128MB blocks = Manageable number of objects.
*   **The "Small File Problem":** If you store millions of 1KB files, you defeat the purpose of the 128MB block size and choke the NameNode.

# Model Answer

---

"The 128MB block size is optimized to **minimize Seek Time** and **maximize NameNode RAM efficiency**.

**1. Disk Mechanics (Seek vs Transfer):**
Finding the start of a block (Seek) takes ~10ms. Reading 128MB takes ~1 second.
*   If we used 4KB blocks, we would spend 99% of our time seeking and 1% reading.
*   With 128MB, we spend 1% seeking and 99% streaming. Ideally, seek time should be < 1% of transfer time.

**2. NameNode Memory Pressure:**
The NameNode stores all block locations in RAM. The more blocks we have, the more RAM we need.
By using massive blocks, we reduce the total number of blocks for a standard Petabyte dataset, allowing the metadata to fit in a reasonable amount of RAM (e.g., 64GB)."

# Diagrams

```text
SEEK TIME vs TRANSFER TIME
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  SCENARIO A: 4KB Blocks (The Bad Way)                                 â•‘
â•‘  [Seek][Read] [Seek][Read] [Seek][Read] ...                           â•‘
â•‘  Spend 10ms to read 0.004MB.                                          â•‘
â•‘  Throughput: Terrible (Like reading a book one word at a time).       â•‘
â•‘                                                                       â•‘
â•‘  SCENARIO B: 128MB Blocks (The Hadoop Way)                            â•‘
â•‘  [Seek] [Read ............................................. ]         â•‘
â•‘  Spend 10ms to read 128MB.                                            â•‘
â•‘  Throughput: Maximum (Like reading a book chapter by chapter).        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## Question 3 â€” Lead Level (Spark vs MapReduce)

**"We have a legacy MapReduce job that takes 10 hours. We rewrote it in Spark and it takes 30 minutes. Why? Explain the architectural difference that causes this speedup."**

# Feedback First

## What You Nailed âœ…
*   **In-Memory:** Correctly stated that Spark does processing in RAM, while MapReduce writes to Disk. This is the #1 answer.
*   **DAG:** Mentioned that Spark plans the whole query (DAG) beforehand.

## What to Tighten Up ğŸ”§
*   **The "Disk I/O Penalty":** Be specific. MapReduce writes to HDFS after *every* Stage (Map -> Disk -> Shuffle -> Reduce -> Disk). Spark pipelines operations and only spills to disk if memory is full.
*   **Start-up Overhead:** MapReduce launches a new JVM container for *every* task. Spark keeps executors running (Long-Lived Containers) and just sends tasks to threads.
*   **Iterative Algorithms:** Mention that for Machine Learning (looping over data 100 times), MapReduce reads from disk 100 times. Spark reads once into RAM (Cache) and loops 100 times in memory.

# Model Answer

---

"The drastic speedup comes from **Eliminating Disk I/O**.

**MapReduce (The Disk Heavy approach):**
Every single step forces a disk write.
1.  Read from HDFS.
2.  Map -> Write intermediate result to Local Disk.
3.  Shuffle -> Read from Disk -> Reduce.
4.  Write final result to HDFS.
*   *Bottleneck:* We are constrained by HDD write speeds (100MB/s).

**Spark (The In-Memory approach):**
Spark constructs a **DAG (Directed Acyclic Graph)**. It pipelines operations.
Map -> Filter -> Project ... all happen in RAM in a single pass. It only writes to disk during a Shuffle or at the very end.
*   *Machine Learning Benefit:* If the job is iterative (like K-Means), Spark caches the data in RAM (`.cache()`) and reuses it 100 times. MapReduce would re-read it from disk 100 times."

# Diagrams

```text
DISK I/O: MAPREDUCE vs SPARK
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  MAPREDUCE (Step-by-Step)                                             â•‘
â•‘  [Map] â”€â”€writeâ”€â”€â–º [DISK] â”€â”€readâ”€â”€â–º [Reduce] â”€â”€writeâ”€â”€â–º [HDFS]         â•‘
â•‘  (Slowest component involved at every stage)                          â•‘
â•‘                                                                       â•‘
â•‘  SPARK (Pipelined)                                                    â•‘
â•‘  [Map] â”€â”€in-ramâ”€â”€â–º [Filter] â”€â”€in-ramâ”€â”€â–º [Reduce] â”€â”€writeâ”€â”€â–º [HDFS]    â•‘
â•‘  (Disk is only touched when absolutely necessary)                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```
