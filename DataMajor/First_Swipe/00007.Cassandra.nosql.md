# Cassandra & Wide-Column NoSQL
### The English Version

---

## What is Cassandra and Why Does it Exist?

In 2008 Facebook had a problem. They needed to power their inbox search feature — storing hundreds of billions of messages across hundreds of millions of users, with writes happening every millisecond from every corner of the planet, and reads needing to return in milliseconds regardless of which data center was closest to the user.

MongoDB couldn't do it. Relational databases couldn't do it. Even other NoSQL databases struggled with the combination of massive write throughput, global distribution, and zero tolerance for downtime.

So Facebook built Cassandra. In 2010 they open-sourced it and donated it to Apache. Today it powers systems at Apple, Netflix, Instagram, Uber, and every major financial institution including Capital One.

The core insight behind Cassandra was radical for its time — **what if we designed a database where there is no single master node, no single point of failure, and every node in the cluster is equal?** Not leader/follower like Kafka or MongoDB. Every node is a peer. Every node can accept reads and writes. The cluster never goes down because there is no single thing that can bring it all down.

---

## Cassandra vs MongoDB — The Critical Distinction

Both are NoSQL. Both scale horizontally. But they solve fundamentally different problems and you must know this distinction cold for the Capital One interview.

MongoDB is optimized for **flexible, rich document storage** where data shapes vary and you need to query data in many different ways. Think customer profiles — rich nested documents with varying attributes queried by many different fields.

Cassandra is optimized for **extreme write throughput and time-series data** where you know your query patterns upfront and need to write millions of records per second with consistent low latency across a globally distributed cluster. Think transaction logs, event streams, IoT sensor readings, audit trails.

The tradeoff Cassandra makes is deliberate — it sacrifices query flexibility for write performance and availability. You design your data model around your queries, not around your entities. This is the opposite of relational thinking and the opposite of MongoDB thinking.

---

## Core Cassandra Concepts in Plain English

**Keyspace** — the top-level namespace, equivalent to a database in relational or MongoDB. Contains tables. Also where you define your replication strategy.

**Table** — looks like a relational table on the surface — rows and columns. But the similarity ends there. Cassandra tables are designed around specific query patterns, not normalized data models.

**Primary Key** — the most critical design decision in Cassandra. Has two parts — the partition key and the clustering key. Understanding these two parts is the entire secret to Cassandra.

**Partition Key** — determines which node in the cluster stores this row. Cassandra hashes the partition key and uses the result to assign data to a node. All rows with the same partition key are stored together on the same node in sorted order. This is why Cassandra is so fast — a query that specifies the partition key goes directly to exactly one node.

**Clustering Key** — determines the sort order of rows within a partition. This is how you get ordered results without sorting — data is physically stored pre-sorted on disk by the clustering key.

**Replication Factor** — how many copies of each partition are stored across the cluster. A replication factor of 3 means every piece of data lives on 3 different nodes. If one node goes down your data is still on 2 others.

**Consistency Level** — how many nodes must confirm a read or write before it's considered successful. This is where Cassandra's famous tunable consistency lives. You can tune between speed and accuracy based on the operation.

---

## The CAP Theorem — Why Cassandra Makes the Choices it Does

Every distributed database must choose how to handle a network partition — when nodes in the cluster can't communicate with each other. The CAP theorem says you can only guarantee two of three properties simultaneously.

**Consistency** — every read returns the most recent write.
**Availability** — every request receives a response.
**Partition Tolerance** — the system continues operating even if network communication between nodes fails.

All distributed databases must have Partition Tolerance — network failures happen in the real world. So the real choice is between Consistency and Availability.

MongoDB chooses **Consistency over Availability** — during a network partition it will refuse writes rather than risk data becoming inconsistent. The primary/secondary model ensures this.

Cassandra chooses **Availability over Consistency** — during a network partition it continues accepting reads and writes on every available node. Data might be temporarily inconsistent between nodes but the system never goes down. This is called **eventual consistency** — all nodes will eventually agree but might be slightly out of sync momentarily.

For Capital One's use cases this tradeoff matters enormously. For transaction logging and audit trails — Cassandra's availability preference is perfect. You never want your audit log to stop accepting writes. For core account balances — you'd choose a CP system because you cannot have two nodes temporarily disagreeing about how much money someone has.

---

## Cassandra's Architecture — The Ring

Cassandra organizes its nodes in a logical ring. Each node is responsible for a range of partition key hashes. When data comes in, Cassandra hashes the partition key and routes it to the node responsible for that hash range.

With a replication factor of 3, the data also gets copied to the next two nodes clockwise around the ring. This means if any node goes down, its neighbors already have copies of its data and can serve requests immediately with no election, no failover process, no downtime.

This is fundamentally different from Kafka's and MongoDB's leader/follower model. In Cassandra there are no leaders. There is no election. Every node is equal. This is why Cassandra is described as having masterless architecture.

---

## Cassandra's Write Path — Why it's So Fast

Understanding why Cassandra achieves such extreme write throughput requires understanding its write path.

When a write arrives at a Cassandra node it does two things immediately and in parallel — it appends the write to an in-memory structure called a **MemTable** and it writes to a **Commit Log** on disk for durability. Both operations are extremely fast because they are sequential — no random disk seeks.

When the MemTable fills up, Cassandra flushes it to disk as an immutable file called an **SSTable** — Sorted String Table. SSTables are never modified. New data creates new SSTables. Periodically Cassandra runs **compaction** — merging multiple SSTables together, removing deleted records, and organizing data for efficient reads.

This write path — sequential writes, immutable files, background compaction — is why Cassandra can sustain millions of writes per second. It never does random disk writes. Everything is sequential.

---

## Cassandra Data Modeling — The Query-First Approach

This is the biggest mindset shift from relational and MongoDB modeling. In Cassandra you don't model your data and then figure out queries. You start with your queries and design your tables to serve them perfectly.

The rule is one table per query pattern. This feels wrong to someone coming from a relational background where you normalize data and use joins. In Cassandra there are no joins. If you need the same data in two different query shapes you create two tables storing the data in both shapes.

This is called **denormalization by design** — and it's intentional. Cassandra trades storage space for read performance. Storage is cheap. Latency is not.

---

## How Cassandra Connects to Your Capital One Stack

In the Capital One real-time fraud detection pipeline we designed — Cassandra is the **write-heavy audit and event store**. Every transaction that flows through Kafka gets written to Cassandra for permanent storage and compliance. The combination of partition key on customer_id and clustering key on timestamp means you can retrieve all transactions for a customer ordered by time in a single partition read — milliseconds at any scale.

Cassandra also fits perfectly as the **feature store** for the ML fraud model. Pre-computed behavioral features per customer, updated by a streaming job, read by the real-time inference engine. Millions of reads and writes per second with consistent single-digit millisecond latency.

---

## Cassandra vs MongoDB — The Cheat Sheet

```
                    CASSANDRA           MONGODB
                    ─────────           ───────
Best for            Write-heavy         Rich documents
                    time-series         Flexible queries
                    known patterns      Variable schemas

Query flexibility   Low — design        High — query
                    queries first       any field

Schema              Fixed per table     Flexible per doc

Consistency         Tunable             Strong (CP)
model               (AP leaning)

Write speed         Extreme             Very fast

Joins               None                $lookup

Use at              Transaction logs    Customer profiles
Capital One         Audit trails        Case management
                    Feature stores      Enrichment store
                    Event history       ML features
```

---

