
# 00015.Flink.Q.md
# Mock Interview — Apache Flink

Same rules — answer in the room, model answer and diagrams after each response.

---

## A) Beginner Level

**Question A1:**  
"What is Apache Flink, and what main problem does it solve compared to traditional batch systems like Spark?"

**Model Answer:**  
Apache Flink is an open-source distributed processing engine optimized for **stateful computations over unbounded (continuous) and bounded (batch) data streams**.  

Its main problem-solving focus: enabling **true low-latency, real-time stream processing** with strong correctness (exactly-once semantics), robust state management, and event-time handling — while treating batch as a finite stream.  

Traditional batch (or micro-batch Spark Streaming) introduces latency floors and makes true real-time hard. Flink processes events as they arrive, maintains large-scale state fault-tolerantly, and unifies batch + streaming under one API/runtime.

---

## B) Warming Up

**Question B1:**  
"Can you explain the core runtime components of a Flink cluster and their responsibilities?"

**Model Answer:**  
Flink runtime has two main process types:

- **JobManager** — central coordinator for a job (in Application Mode):  
  - Accepts job submission  
  - Translates JobGraph → ExecutionGraph  
  - Schedules tasks to TaskManagers  
  - Manages checkpoints, recovery, failover  

- **TaskManager** — worker processes (many):  
  - Execute parallel tasks in **task slots**  
  - Run operator logic (map, window, join…)  
  - Manage local state  
  - Buffer & shuffle data streams  

```
Job Submission
      │
      ▼
JobManager ────► Assigns tasks
      │
      ├────► TaskManager-1 (slots)
      ├────► TaskManager-2 (slots)
      └────► TaskManager-N (slots)
```

In Kubernetes, each job often gets its own cluster (Application Mode).

---

## C) Getting Serious

**Question C1:**  
"What is the role of Watermarks in Flink, and how do they enable event-time processing?"

**Model Answer:**  
Watermarks are special timestamped control records that flow through the stream and tell downstream operators: "I have seen all events with event-time ≤ T".

They drive **event-time windows**:

1. Events carry event-time timestamp
2. Watermark generators (monotonous or bounded-out-of-orderness) produce watermarks
3. Window operator buffers events until watermark ≥ window-end → triggers computation
4. Late events can be side-output or dropped (allowed lateness)

Without watermarks, windows would never close in unbounded streams.

Example:

```
Event-time: 10:02 ──► Watermark 10:01 ──► Window 10:00–10:05 fires
```

This handles out-of-order and delayed data correctly.

---

## D) Data Engineer Level

**Question D1:**  
"Explain Flink's checkpoint mechanism and how it achieves exactly-once processing semantics."

**Model Answer:**  
Checkpoints are periodic global consistent snapshots of:

- Operator state
- Stream position (offsets)

Mechanism (Chandy-Lamport style):

1. JobManager injects **checkpoint barriers** into sources
2. Barriers flow downstream — when operator receives barrier on all inputs, it snapshots state atomically
3. State snapshot written to durable storage (S3, HDFS…)
4. Acknowledgement flows back to JobManager

On failure:

- Restore latest checkpoint
- Rewind sources to checkpointed offsets
- Replay events → state rebuilt exactly

Exactly-once achieved via:

- Checkpoint barriers never overtake events
- Two-phase commit sinks (e.g., Kafka) align with barriers

RocksDB backend + incremental checkpoints make large-state feasible.

---

## E) Lead Data Engineer Level

**Question E1:**  
"How would you design a real-time streaming pipeline in Flink to compute sliding-window session-based user engagement metrics from Kafka, handling late data and scaling to 1M+ events/sec?"

**Model Answer:**  
Architecture:

1. **Source** — Kafka (exactly-once)
2. **KeyBy** — user_id
3. **ProcessFunction** or **KeyedProcessFunction** — sessionization (gap > 30 min closes session)
4. **Event-time** windows — sliding 5-min every 1-min
5. **Aggregate** — count events, unique pages, duration
6. **Watermarks** — bounded out-of-orderness (e.g., 2 min)
7. **Side outputs** — late events > allowed lateness
8. **Sink** — Paimon/Iceberg for analytics + downstream Kafka for alerts

Scaling:

- Reactive Mode autoscaling
- Increase parallelism per operator
- RocksDB state backend + incremental checkpoints
- Tune checkpoint interval (30–60s), timeout, alignment

Monitoring: Flink UI, Prometheus metrics (backpressure, latency, state size).

---

## F) Final Boss

**Question F1:**  
"In a streaming lakehouse architecture using Flink 2.0+, explain Materialized Tables and how they simplify real-time analytics compared to traditional stream processing jobs."

**Model Answer:**  
Materialized Tables (introduced/refined in Flink 2.0) let users define real-time tables using SQL that automatically maintain latest state from streaming sources — hiding much of the stream complexity.

Example:

```sql
CREATE MATERIALIZED TABLE user_metrics AS
SELECT
  user_id,
  COUNT(*) AS event_count,
  MAX(event_time) AS last_seen
FROM kafka_events
GROUP BY user_id;
```

Flink handles:

- Streaming ingestion
- State management
- Incremental updates
- Materialization to Paimon/Iceberg
- Query freshness

Advantages vs traditional jobs:

- No need to write/maintain custom streaming code
- Business users write SQL
- Unified batch + stream view
- Automatic fault-tolerance & scaling
- Better for Streaming Lakehouse (Flink + Paimon)

Trade-off: less control over low-level optimizations, but huge productivity gain for analytics use cases.