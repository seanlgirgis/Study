
# Mock Interview â€” MongoDB & NoSQL

Same rules â€” answer like you're in the room. Model answer and diagrams after each response.

---

## Question 1 â€” Warm Up

**"Can you explain what NoSQL is, why it was created, and how MongoDB specifically differs from a traditional relational database like PostgreSQL or Oracle?"**

# Feedback First

---

## What You Nailed âœ…

**"Big companies got flooded with huge, messy, fast-changing data"** â€” perfect origin story. Concise and accurate.

**Three scaling problems identified** â€” rigid schemas, slow scaling, expensive at scale. All correct.

**Document vs row distinction** â€” cleanly explained. "Each one can have different fields" captures the core flexibility perfectly.

**Schema flexibility tradeoff** â€” correctly identified that relational requires upfront planning while MongoDB allows change. Shows maturity.

**"Many places use both"** â€” this is the senior engineer answer. Knowing that the real world uses polyglot persistence rather than picking one winner signals production experience.

**Best use cases** â€” correctly mapped relational to transactions and accuracy, MongoDB to speed and flexibility.

---

## What to Tighten Up ğŸ”§

**Missing the three V's of big data context** â€” giving the origin story more technical framing elevates it:

*"The NoSQL movement emerged around 2009-2010 driven by the three V's â€” Volume, Velocity, and Variety. Volume because datasets grew from gigabytes to petabytes. Velocity because data needed to be written and read in milliseconds not seconds. Variety because data stopped fitting neatly into rows and columns."*

**Missing BSON** â€” MongoDB specifically uses BSON not plain JSON. One sentence matters:

*"MongoDB stores data as BSON â€” Binary JSON â€” which extends JSON with additional data types like dates, integers, and binary data, and is optimized for fast serialization and deserialization."*

**Missing the join problem specifically** â€” this is the core technical reason NoSQL was needed:

*"The fundamental problem with relational databases at scale was joins. A query joining five tables with billions of rows each requires the database to correlate records across massive datasets â€” it becomes catastrophically slow. MongoDB solves this by embedding related data inside a single document, eliminating the join entirely."*

**Missing horizontal vs vertical scaling distinction** â€” your answer said "harder to add servers" but the technical framing is more precise:

*"Relational databases scale vertically â€” you buy a bigger, more expensive single server. MongoDB scales horizontally through sharding â€” you add more commodity servers and MongoDB distributes data across them automatically. At Capital One scale, horizontal scaling is the only economically viable option."*

---

# Model Answer

---

*"NoSQL stands for Not Only SQL â€” it's a family of database technologies that emerged around 2009 to 2010 to solve problems that relational databases couldn't handle at internet scale.*

**Why NoSQL was created:**

*The trigger was the three V's of big data â€” Volume, Velocity, and Variety. Volume because companies like Google, Amazon, and Facebook were dealing with petabytes of data, far beyond what a single relational database server could hold. Velocity because modern applications need reads and writes in milliseconds â€” a relational database doing complex joins across billion-row tables simply cannot deliver that. Variety because data stopped fitting neatly into rows and columns â€” user profiles, social posts, product catalogs, IoT sensor readings all have irregular, nested, variable structures that a fixed schema handles poorly.*

*Relational databases had three specific architectural limitations at this scale. First, rigid schemas â€” changing a table structure on a billion-row table requires a migration that can lock the table for hours. Second, vertical scaling â€” relational databases scale by buying bigger, more expensive single servers, which has a hard physical and economic ceiling. Third, the join problem â€” reconstructing a customer profile from five normalized tables with billions of rows each requires correlating massive datasets, which becomes catastrophically slow.*

*NoSQL solved all three â€” flexible schemas that change without migrations, horizontal scaling by adding commodity servers, and embedding related data together to eliminate joins.*

**How MongoDB specifically differs from PostgreSQL or Oracle:**

*MongoDB is a document database. Instead of storing data in rows and columns it stores self-contained documents in BSON format â€” Binary JSON â€” which extends standard JSON with additional data types optimized for fast serialization.*

*The fundamental difference is the data model. In PostgreSQL a customer record is spread across multiple normalized tables â€” a customers table, an addresses table, an accounts table, a transactions table â€” and you reconstruct the full customer picture with a multi-table join. In MongoDB that same customer is a single document containing all their information nested together. One read operation retrieves everything. No joins.*

*Schema is the second major difference. PostgreSQL requires you to define every column upfront. Adding a new field means an ALTER TABLE statement that can be expensive at scale. MongoDB has no enforced schema by default â€” you can add new fields to documents at any time without touching existing documents. Capital One would add schema validation rules on top to maintain data quality while keeping the flexibility.*

*Scaling is the third difference. PostgreSQL scales vertically â€” you buy a bigger server. MongoDB scales horizontally through sharding â€” you add more servers and MongoDB automatically distributes your data across them using a shard key. When Capital One's customer database grows from 50 million to 100 million customers, you add shards rather than buying a more expensive machine.*

*The honest answer for a bank like Capital One is that both have a role. Core financial transactions â€” debits, credits, transfers â€” live in relational databases because ACID compliance and complex reporting are non-negotiable there. Customer profiles, fraud case management, enrichment stores for ML models â€” those live in MongoDB because the data is naturally document-shaped and flexibility and read speed matter more than relational integrity."*

---

# Diagrams

```
WHY NOSQL WAS CREATED â€” THE THREE V'S
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                       â•‘
â•‘   VOLUME              VELOCITY             VARIETY                   â•‘
â•‘   â”€â”€â”€â”€â”€â”€              â”€â”€â”€â”€â”€â”€â”€â”€             â”€â”€â”€â”€â”€â”€â”€                   â•‘
â•‘   Gigabytes           Seconds              Rows & Columns            â•‘
â•‘      â”‚                   â”‚                     â”‚                     â•‘
â•‘      â”‚ grew to           â”‚ needed to be        â”‚ became              â•‘
â•‘      â–¼                   â–¼                     â–¼                     â•‘
â•‘   Petabytes           Milliseconds         Nested JSON               â•‘
â•‘                                            Arrays                    â•‘
â•‘                                            Variable fields           â•‘
â•‘                                            Unstructured text         â•‘
â•‘                                                                       â•‘
â•‘   Relational databases could not handle all three simultaneously     â•‘
â•‘   NoSQL was built specifically for this combination                  â•‘
â•‘                                                                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


RELATIONAL VS MONGODB â€” DATA MODEL
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                       â•‘
â•‘  RELATIONAL (PostgreSQL)          MONGODB                            â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”€â”€â”€â”€â”€â”€â”€                            â•‘
â•‘                                                                       â•‘
â•‘  customers table:                 customers collection:              â•‘
â•‘  â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”           {                                  â•‘
â•‘  â”‚ id â”‚ name  â”‚ email â”‚             "_id": "C001",                   â•‘
â•‘  â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤             "name": "Alice Johnson",         â•‘
â•‘  â”‚C001â”‚ Alice â”‚a@e.comâ”‚             "email": "a@e.com",              â•‘
â•‘  â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜             "address": {                     â•‘
â•‘                                       "city": "McLean",              â•‘
â•‘  addresses table:                     "state": "VA"                  â•‘
â•‘  â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”            },                               â•‘
â•‘  â”‚ id â”‚  city  â”‚ state â”‚            "accounts": [                    â•‘
â•‘  â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤              {"type": "checking",           â•‘
â•‘  â”‚C001â”‚ McLean â”‚  VA   â”‚               "balance": 5420.00},          â•‘
â•‘  â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜              {"type": "savings",            â•‘
â•‘                                        "balance": 28750.00}          â•‘
â•‘  accounts table:                    ],                               â•‘
â•‘  â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         "risk_score": 0.12,             â•‘
â•‘  â”‚ id â”‚   type   â”‚ balance â”‚         "is_premium": true              â•‘
â•‘  â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤       }                                 â•‘
â•‘  â”‚C001â”‚ checking â”‚ 5420.00 â”‚                                         â•‘
â•‘  â”‚C001â”‚ savings  â”‚28750.00 â”‚       ONE document                      â•‘
â•‘  â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       ONE read                          â•‘
â•‘                                    NO joins                          â•‘
â•‘  THREE tables                                                        â•‘
â•‘  ONE join query                                                      â•‘
â•‘  Gets slower as tables grow                                          â•‘
â•‘                                                                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


SCALING â€” VERTICAL VS HORIZONTAL
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                       â•‘
â•‘  RELATIONAL â€” VERTICAL SCALING         MONGODB â€” HORIZONTAL SCALING  â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â•‘
â•‘                                                                       â•‘
â•‘        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”   â•‘
â•‘        â”‚ BIGGEST â”‚                    â”‚Shard 1â”‚â”‚Shard 2â”‚â”‚Shard 3â”‚   â•‘
â•‘        â”‚ SERVER  â”‚                    â”‚C001-  â”‚â”‚C334K- â”‚â”‚C667K- â”‚   â•‘
â•‘        â”‚ MONEY   â”‚                    â”‚C333K  â”‚â”‚C666K  â”‚â”‚C999K  â”‚   â•‘
â•‘        â”‚ CAN BUY â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”˜   â•‘
â•‘        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â–²        â–²        â–²      â•‘
â•‘             â–²                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â•‘
â•‘             â”‚                                       â”‚               â•‘
â•‘        Hit ceiling                          mongos router           â•‘
â•‘        Buy even bigger                      directs queries         â•‘
â•‘        server ğŸ’¸                            to right shard          â•‘
â•‘                                                                      â•‘
â•‘        Hard physical limit                 Add shards = add scale   â•‘
â•‘        Expensive                           Commodity servers        â•‘
â•‘        Single point of failure             Fault tolerant           â•‘
â•‘                                                                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


TERM MAPPING â€” RELATIONAL TO MONGODB
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                       â•‘
â•‘   RELATIONAL          MONGODB              NOTES                     â•‘
â•‘   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”€â”€â”€â”€â”€â”€â”€              â”€â”€â”€â”€â”€                     â•‘
â•‘   Database      â•â•â–º   Database             Same concept              â•‘
â•‘   Table         â•â•â–º   Collection           No fixed schema           â•‘
â•‘   Row           â•â•â–º   Document             JSON/BSON format          â•‘
â•‘   Column        â•â•â–º   Field                Varies per document       â•‘
â•‘   Primary Key   â•â•â–º   _id                  Auto-generated if needed  â•‘
â•‘   Foreign Key   â•â•â–º   Reference/Embed      Design choice             â•‘
â•‘   JOIN          â•â•â–º   $lookup / Embed      Embed = no join needed    â•‘
â•‘   INDEX         â•â•â–º   Index                Same concept              â•‘
â•‘   VIEW          â•â•â–º   View                 Same concept              â•‘
â•‘   SQL           â•â•â–º   MQL                  MongoDB Query Language    â•‘
â•‘   ACID Txn      â•â•â–º   Multi-doc Txn        Added in MongoDB 4.0      â•‘
â•‘                                                                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


WHEN TO USE WHICH AT CAPITAL ONE
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                       â•‘
â•‘   USE RELATIONAL (PostgreSQL/Oracle) WHEN:                           â•‘
â•‘   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                  â•‘
â•‘   âœ… Core financial transactions â€” debits, credits, transfers        â•‘
â•‘   âœ… Regulatory reporting requiring complex joins                    â•‘
â•‘   âœ… ACID compliance across multiple entities is non-negotiable      â•‘
â•‘   âœ… Data is highly structured and consistent                        â•‘
â•‘                                                                       â•‘
â•‘   USE MONGODB WHEN:                                                   â•‘
â•‘   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                  â•‘
â•‘   âœ… Customer 360 profiles â€” nested, variable attributes             â•‘
â•‘   âœ… Fraud case management â€” each case has different evidence        â•‘
â•‘   âœ… ML feature store â€” hundreds of behavioral features per customer â•‘
â•‘   âœ… Transaction enrichment â€” fast lookup during real-time pipeline  â•‘
â•‘   âœ… Product catalogs â€” different fields per product type            â•‘
â•‘                                                                       â•‘
â•‘   CAPITAL ONE LIKELY USES BOTH â€” polyglot persistence                â•‘
â•‘   Right database for the right job                                   â•‘
â•‘                                                                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---
---
---

## Question 2 â€” Stepping Up

**"Walk me through MongoDB's architecture â€” replica sets, sharding, and the WiredTiger storage engine. How do these components work together to give you both high availability and horizontal scale?"**

# Feedback First

---

## What You Nailed âœ…

**Replica set primary/secondary model** â€” correctly explained. One primary handles writes, secondaries replicate, automatic election on failure. Accurate and complete.

**"Automatic election"** â€” mentioning this specifically shows you understand that MongoDB's high availability is self-healing, not manual.

**Sharding components** â€” correctly identified all three pieces â€” shards, config servers, and mongos routers. Most candidates miss the config server entirely.

**"Each shard holds part of the data"** â€” correct. And giving an example like user ID or region shows you understand the shard key concept.

**WiredTiger as the storage layer** â€” correctly positioned it as the underlying engine and correctly identified compression, caching, and crash recovery.

**"Each shard is itself a replica set"** â€” your closing summary implied this correctly. This is the key insight that combines both concepts.

**The file cabinet analogy** â€” simple and memorable for WiredTiger.

---

## What to Tighten Up ğŸ”§

**Missing the shard key design importance.** This is the most critical MongoDB architecture decision and deserves more attention:

*"The shard key is the most important design decision in a sharded MongoDB deployment. A bad shard key â€” one with low cardinality or that causes hotspots â€” can make sharding worse than not sharding at all. For Capital One's customer collection, customer_id is a good shard key because it has high cardinality, distributes writes evenly, and queries are almost always scoped to a single customer."*

**Missing ranged vs hashed sharding.** Two sentences would complete the picture:

*"MongoDB supports two sharding strategies. Range-based sharding groups similar shard key values together â€” good for range queries but can cause hotspots if values are sequential. Hashed sharding distributes documents by hashing the shard key â€” guarantees even distribution but makes range queries less efficient."*

**Missing the odd-number rule for replica sets.** Critical detail:

*"Replica sets always run an odd number of members â€” typically three or five â€” because elections require a majority vote to elect a new primary. With two members, if one goes down you can't reach majority and the set becomes read-only. Three members means one failure still leaves two members to reach majority and elect a new primary."*

**Missing WiredTiger document-level locking.** This is its key performance feature:

*"WiredTiger's most important performance characteristic is document-level concurrency control â€” multiple operations on different documents can run simultaneously without blocking each other. The older MMAPv1 engine used collection-level locking, meaning one write blocked all other writes to the entire collection. WiredTiger eliminated that bottleneck."*

---

# Model Answer

---

*"MongoDB's architecture has three layers that work together to deliver both high availability and horizontal scale â€” replica sets for reliability, sharding for scale, and WiredTiger for storage efficiency.*

**Replica Sets:**

*A replica set is a group of MongoDB instances â€” always an odd number, typically three â€” that all hold identical copies of the same data. The odd number is deliberate â€” elections require a majority vote to choose a new primary, and an even number could result in a tie.*

*One member is the Primary â€” it receives all write operations and propagates changes to the other members through an operation log called the oplog. The other members are Secondaries â€” they continuously replicate from the Primary's oplog and stay current within milliseconds.*

*If the Primary goes down â€” hardware failure, network partition, planned maintenance â€” the Secondaries detect the absence of heartbeats and automatically hold an election. Within typically 10 to 30 seconds a new Primary is elected and the cluster resumes accepting writes. No human intervention required. This is MongoDB's high availability story.*

*Secondaries can also serve read operations, which is useful for distributing read-heavy workloads. Capital One might route fraud model feature lookups to secondaries to avoid adding read pressure to the Primary that's handling all transaction writes.*

**Sharding:**

*Sharding is MongoDB's horizontal scaling mechanism. When a single replica set can no longer handle your data volume or write throughput, you shard â€” splitting the data across multiple replica sets called shards.*

*The architecture has three components. The shards themselves â€” each one is a full replica set holding a subset of the total data. The config servers â€” a small replica set that stores metadata about which shard holds which data ranges. And the mongos routers â€” lightweight processes that sit in front of everything and direct incoming queries to the correct shard based on the shard key.*

*The shard key is the most critical design decision in a MongoDB deployment. It determines how data is distributed across shards. A good shard key has high cardinality â€” many distinct values â€” and distributes writes evenly to avoid hotspots. For Capital One's customer collection, customer_id is an ideal shard key. For a transactions collection, a compound key of customer_id plus date distributes data evenly while supporting the most common query patterns.*

*MongoDB supports two sharding strategies. Range-based sharding groups documents with similar shard key values on the same shard â€” good for range queries like "all transactions between date A and date B" but risks hotspots if values are sequential or clustered. Hashed sharding applies a hash function to the shard key and distributes documents based on the hash â€” guarantees even distribution but sacrifices range query efficiency.*

**WiredTiger Storage Engine:**

*WiredTiger is the storage engine that runs underneath everything â€” it handles how data is physically written to and read from disk on each node.*

*Its most important performance characteristic is document-level concurrency control. Multiple write operations on different documents execute simultaneously without blocking each other. The older MMAPv1 engine used collection-level locking â€” one write blocked all other writes to the entire collection. At Capital One's transaction volume that would be catastrophic. WiredTiger eliminated that bottleneck entirely.*

*WiredTiger also applies compression by default â€” Snappy compression for data files and Zlib for the journal. This typically reduces storage footprint by 60 to 80 percent compared to uncompressed storage, which at Capital One scale translates to significant infrastructure cost savings.*

*Finally WiredTiger uses checkpointing â€” writing a consistent snapshot of all data to disk every 60 seconds by default. Combined with a write-ahead journal that logs every operation, WiredTiger can recover to a consistent state after a crash with minimal data loss.*

**How They Work Together:**

*Each shard is itself a full replica set â€” so you get both horizontal scale and high availability simultaneously. A three-shard cluster with three-member replica sets means nine MongoDB instances total, any one of which can fail without impact. WiredTiger running on every node ensures each instance is reading and writing efficiently with compression and document-level concurrency.*

*For Capital One â€” a customer_profiles collection sharded by customer_id across three shards, each shard a three-member replica set, WiredTiger compressed and checkpointed â€” gives you a system that handles hundreds of millions of customer documents, survives any individual server failure, and scales by simply adding shards as the customer base grows."*

---

# Architecture Diagrams

```
REPLICA SET â€” HIGH AVAILABILITY
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                       â•‘
â•‘                    REPLICA SET (3 members)                           â•‘
â•‘                                                                       â•‘
â•‘         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â•‘
â•‘         â”‚                                         â”‚                  â•‘
â•‘         â–¼                                         â–¼                  â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    oplog    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚                  â•‘
â•‘  â”‚  PRIMARY    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ SECONDARY 1 â”‚      â”‚                  â•‘
â•‘  â”‚             â”‚             â”‚             â”‚      â”‚                  â•‘
â•‘  â”‚ All writes  â”‚    oplog    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”‚                  â•‘
â•‘  â”‚ All reads   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ SECONDARY 2 â”‚      â”‚                  â•‘
â•‘  â”‚ (default)   â”‚             â”‚             â”‚      â”‚                  â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜      â”‚                  â•‘
â•‘         â”‚                          â”‚              â”‚                  â•‘
â•‘         â”‚ heartbeat every 2s       â”‚ heartbeat    â”‚                  â•‘
â•‘         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚                  â•‘
â•‘                                                   â”‚                  â•‘
â•‘  PRIMARY GOES DOWN:                               â”‚                  â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                â”‚                  â•‘
â•‘  Secondaries detect missing heartbeat             â”‚                  â•‘
â•‘         â”‚                                         â”‚                  â•‘
â•‘         â–¼                                         â”‚                  â•‘
â•‘  Election triggered â€” majority vote needed        â”‚                  â•‘
â•‘  2 remaining members = majority of 3 âœ…           â”‚                  â•‘
â•‘         â”‚                                         â”‚                  â•‘
â•‘         â–¼                                         â”‚                  â•‘
â•‘  Secondary 1 elected new PRIMARY                  â”‚                  â•‘
â•‘  Recovery: 10-30 seconds                          â”‚                  â•‘
â•‘  Zero data loss (oplog replicated) âœ…             â”‚                  â•‘
â•‘                                                   â”‚                  â•‘
â•‘  WHY ODD NUMBERS:                                 â”‚                  â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                 â”‚                  â•‘
â•‘  2 members: 1 fails â†’ 1 remaining                 â”‚                  â•‘
â•‘             cannot reach majority â†’ READ ONLY âŒ  â”‚                  â•‘
â•‘  3 members: 1 fails â†’ 2 remaining                 â”‚                  â•‘
â•‘             majority reached â†’ NEW PRIMARY âœ…     â”‚                  â•‘
â•‘  5 members: 2 fail  â†’ 3 remaining                 â”‚                  â•‘
â•‘             majority reached â†’ NEW PRIMARY âœ…     â”‚                  â•‘
â•‘                                                   â”‚                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                                                    â”‚
                                                    â”‚
SHARDING â€” HORIZONTAL SCALE                        â”‚
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                   â”‚                  â•‘
â•‘   APPLICATION                                     â”‚                  â•‘
â•‘        â”‚                                          â”‚                  â•‘
â•‘        â–¼                                          â”‚                  â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚                  â•‘
â•‘  â”‚   mongos    â”‚  â—„â”€â”€ Query router                â”‚                  â•‘
â•‘  â”‚   ROUTER    â”‚      Directs to right shard      â”‚                  â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                  â”‚                  â•‘
â•‘         â”‚                                         â”‚                  â•‘
â•‘         â”‚ consults                                â”‚                  â•‘
â•‘         â–¼                                         â”‚                  â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚                  â•‘
â•‘  â”‚   CONFIG    â”‚  â—„â”€â”€ Stores chunk metadata       â”‚                  â•‘
â•‘  â”‚   SERVERS   â”‚      "C001-C333K lives on Shard1"â”‚                  â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                  â”‚                  â•‘
â•‘         â”‚                                         â”‚                  â•‘
â•‘         â”‚ routes to                               â”‚                  â•‘
â•‘         â–¼                                         â”‚                  â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚                  â•‘
â•‘  â”‚              SHARDS                      â”‚     â”‚                  â•‘
â•‘  â”‚                                          â”‚     â”‚                  â•‘
â•‘  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚     â”‚                  â•‘
â•‘  â”‚  â”‚ SHARD 1  â”‚ â”‚ SHARD 2  â”‚ â”‚ SHARD 3  â”‚ â”‚     â”‚                  â•‘
â•‘  â”‚  â”‚(Replica  â”‚ â”‚(Replica  â”‚ â”‚(Replica  â”‚ â”‚     â”‚                  â•‘
â•‘  â”‚  â”‚  Set)    â”‚ â”‚  Set)    â”‚ â”‚  Set)    â”‚ â”‚     â”‚                  â•‘
â•‘  â”‚  â”‚          â”‚ â”‚          â”‚ â”‚          â”‚ â”‚     â”‚                  â•‘
â•‘  â”‚  â”‚ C001 to  â”‚ â”‚ C334K to â”‚ â”‚ C667K to â”‚ â”‚     â”‚                  â•‘
â•‘  â”‚  â”‚ C333K    â”‚ â”‚ C666K    â”‚ â”‚ C999K    â”‚ â”‚     â”‚                  â•‘
â•‘  â”‚  â”‚          â”‚ â”‚          â”‚ â”‚          â”‚ â”‚     â”‚                  â•‘
â•‘  â”‚  â”‚ P+S1+S2  â”‚ â”‚ P+S1+S2  â”‚ â”‚ P+S1+S2  â”‚ â”‚     â”‚                  â•‘
â•‘  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚     â”‚                  â•‘
â•‘  â”‚  Each shard = full replica set âœ…        â”‚     â”‚                  â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚                  â•‘
â•‘                                                   â”‚                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                                                    â”‚
WIREDTIGER â€” STORAGE ENGINE                        â”‚
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                   â”‚                  â•‘
â•‘  EVERY NODE IN EVERY SHARD RUNS WIREDTIGER        â”‚                  â•‘
â•‘                                                   â”‚                  â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚                  â•‘
â•‘  â”‚              WiredTiger                    â”‚   â”‚                  â•‘
â•‘  â”‚                                            â”‚   â”‚                  â•‘
â•‘  â”‚  Document-level     Compression            â”‚   â”‚                  â•‘
â•‘  â”‚  concurrency   â”€â”€â–º  Snappy: data files     â”‚   â”‚                  â•‘
â•‘  â”‚                     Zlib:   journal        â”‚   â”‚                  â•‘
â•‘  â”‚  Many writes on     60-80% size reduction  â”‚   â”‚                  â•‘
â•‘  â”‚  different docs     at Capital One scale   â”‚   â”‚                  â•‘
â•‘  â”‚  simultaneously âœ…  = massive cost saving  â”‚   â”‚                  â•‘
â•‘  â”‚                                            â”‚   â”‚                  â•‘
â•‘  â”‚  Checkpointing â”€â”€â–º  Snapshot every 60s     â”‚   â”‚                  â•‘
â•‘  â”‚                     + write-ahead journal  â”‚   â”‚                  â•‘
â•‘  â”‚                     = crash recovery âœ…    â”‚   â”‚                  â•‘
â•‘  â”‚                                            â”‚   â”‚                  â•‘
â•‘  â”‚  Cache â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º  Frequently accessed    â”‚   â”‚                  â•‘
â•‘  â”‚                     docs stay in RAM       â”‚   â”‚                  â•‘
â•‘  â”‚                     = fast reads âœ…        â”‚   â”‚                  â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚                  â•‘
â•‘                                                   â”‚                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


SHARD KEY DESIGN â€” CRITICAL DECISION
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                       â•‘
â•‘  BAD SHARD KEY              GOOD SHARD KEY                           â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€               â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                          â•‘
â•‘                                                                       â•‘
â•‘  created_date               customer_id                              â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                              â•‘
â•‘  All new writes go to       Writes distributed                       â•‘
â•‘  "today" shard              evenly across all shards                 â•‘
â•‘                                                                       â•‘
â•‘  Shard 1: JAN â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   Shard 1: C001-C333K â–ˆâ–ˆâ–ˆâ–ˆ                 â•‘
â•‘  Shard 2: FEB â–ˆâ–ˆâ–ˆâ–ˆ         Shard 2: C334K-C666K â–ˆâ–ˆâ–ˆâ–ˆ                â•‘
â•‘  Shard 3: TODAY â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  Shard 3: C667K-C999K â–ˆâ–ˆâ–ˆâ–ˆ                â•‘
â•‘                                                                       â•‘
â•‘  HOTSPOT âŒ                 EVEN DISTRIBUTION âœ…                     â•‘
â•‘                                                                       â•‘
â•‘  RANGE SHARDING             HASHED SHARDING                          â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€             â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                         â•‘
â•‘  Good for: range queries    Good for: write distribution             â•‘
â•‘  Risk: hotspots             Risk: range queries hit all shards       â•‘
â•‘                                                                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


THE COMPLETE PICTURE â€” ALL THREE LAYERS
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                       â•‘
â•‘  APPLICATION REQUEST: "Get customer C001 profile"                    â•‘
â•‘         â”‚                                                             â•‘
â•‘         â–¼                                                             â•‘
â•‘  mongos router checks config server                                  â•‘
â•‘  "C001 lives on Shard 1" â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â•‘
â•‘                                                         â”‚            â•‘
â•‘         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â•‘
â•‘         â–¼                                                             â•‘
â•‘  SHARD 1 (Replica Set)                                               â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â•‘
â•‘  â”‚  PRIMARY                                        â”‚                 â•‘
â•‘  â”‚  WiredTiger checks cache â†’ found in RAM âœ…      â”‚                 â•‘
â•‘  â”‚  Returns document in < 10ms                     â”‚                 â•‘
â•‘  â”‚                                                 â”‚                 â•‘
â•‘  â”‚  Meanwhile oplog replicating to:                â”‚                 â•‘
â•‘  â”‚  Secondary 1 âœ…  Secondary 2 âœ…                 â”‚                 â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â•‘
â•‘         â”‚                                                             â•‘
â•‘         â–¼                                                             â•‘
â•‘  Customer document returned to application                           â•‘
â•‘  Total time: < 10ms âœ…                                               â•‘
â•‘  High availability: 2 replicas ready to take over âœ…                 â•‘
â•‘  Horizontal scale: add Shard 4 when needed âœ…                        â•‘
â•‘                                                                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---
---
---
## Question 3 â€” Getting Serious

**"How would you model a Capital One customer's data in MongoDB? Walk me through your document design decisions â€” what you embed, what you reference, and why. Then show me how you would query it efficiently."**

# Feedback First

---

## What You Nailed âœ…

**Three collection design** â€” customers, accounts, transactions is exactly the right structure. Clean separation of concerns.

**Embed vs reference reasoning** â€” this is the core MongoDB design decision and you nailed the logic. Small and always needed together = embed. Large and growing = reference.

**Addresses embedded** â€” correct. A customer has 1-3 addresses, always needed with the profile, never queried independently.

**Accounts referenced** â€” correct. Balances change frequently, you don't want to update the entire customer document every time a balance changes.

**Transactions separate** â€” correct. Transactions are unbounded â€” a customer could have millions. Embedding would make documents grow without limit.

**Index awareness** â€” mentioning that customer_id and account_id need indexes on the transactions and accounts collections shows production thinking.

**Query examples** â€” all three queries are correct and realistic.

**"No duplication, easy updates"** â€” correctly identified the tradeoff between embedding for read performance and referencing for write performance.

---

## What to Tighten Up ğŸ”§

**Missing the document size limit context.** MongoDB has a 16MB document size limit. Mentioning this justifies your referencing decisions technically:

*"MongoDB enforces a 16MB maximum document size. If we embedded transactions directly in the customer document, a high-volume customer with millions of transactions would eventually hit that limit and writes would fail. Separating transactions into their own collection removes that ceiling entirely."*

**Missing the $lookup for joins.** When you do need to combine data across collections MongoDB uses $lookup â€” the NoSQL equivalent of a SQL JOIN:

```javascript
// Get customer with their accounts in one query
db.customers.aggregate([
  { $match: { _id: "C001" } },
  { $lookup: {
      from: "accounts",
      localField: "account_ids",
      foreignField: "_id",
      as: "accounts"
    }
  }
])
```

**Missing compound indexes.** Your queries mentioned indexes but didn't specify compound indexes which are critical for the transaction query pattern:

*"For transactions I'd create a compound index on account_id plus date â€” this supports both filtering by account and sorting by date in a single index scan. Without the compound index, MongoDB would use the account_id index to find matching documents then do an expensive in-memory sort."*

**Missing the schema validation point.** In a financial institution you'd never leave MongoDB completely schema-free:

*"Even though MongoDB is schema-flexible, at Capital One I'd add schema validation rules â€” requiring amount to be a positive number, status to be one of an approved set of values, and _id to follow our transaction ID format. This gives us NoSQL flexibility while maintaining financial data integrity."*

**Missing the fraud-specific enrichment document.** For a Capital One context you'd want a fourth collection:

*"I'd add a fourth collection â€” customer_risk_profiles â€” containing pre-computed ML features and behavioral statistics per customer. This is read heavily by the real-time fraud pipeline and written to by a batch job. Keeping it separate from the core customer document means the fraud pipeline's heavy reads don't compete with customer profile updates."*

---

# Model Answer

---

*"Document design in MongoDB is fundamentally about answering one question for every piece of data â€” do I embed this or reference it? The answer drives everything else.*

**The Golden Rule:**

*Embed when data is small, bounded, and always accessed together with its parent. Reference when data is large, unbounded, or updated independently of its parent. For Capital One's customer data this leads naturally to four collections.*

**Collection 1 â€” customers:**

```javascript
{
  "_id": "C001",
  "name": "Alice Johnson",
  "email": "alice@capitalone.com",
  "phone": "+1-703-555-0101",
  "addresses": [                    // EMBEDDED â€” small, bounded, always needed
    {
      "type": "home",
      "street": "123 Main St",
      "city": "McLean",
      "state": "VA",
      "zip": "22102",
      "is_primary": true
    },
    {
      "type": "work",
      "street": "1680 Capital One Dr",
      "city": "McLean",
      "state": "VA",
      "zip": "22102",
      "is_primary": false
    }
  ],
  "account_ids": ["A001", "A002"],  // REFERENCED â€” accounts live separately
  "member_since": "2018-03-15",
  "tier": "Premium",
  "is_active": true
}
```

*Addresses are embedded because a customer has at most 3-5 addresses, they're always needed when loading the profile, and they're never queried independently. Account IDs are referenced because account data changes frequently â€” balances update constantly â€” and we don't want to rewrite the entire customer document every time a balance changes.*

**Collection 2 â€” accounts:**

```javascript
{
  "_id": "A001",
  "customer_id": "C001",           // REFERENCE back to customer
  "type": "checking",
  "balance": 5420.00,
  "available_balance": 5420.00,
  "currency": "USD",
  "status": "active",
  "opened_date": "2018-03-15",
  "routing_number": "051405515",
  "account_number_last4": "4821"
}
```

*Accounts are separate because balances change with every transaction. If accounts were embedded in the customer document, every single transaction would require rewriting the entire customer document â€” expensive and creating write contention. Separate collection means balance updates touch only the account document.*

**Collection 3 â€” transactions:**

```javascript
{
  "_id": "T001",
  "account_id": "A001",            // REFERENCE to account
  "customer_id": "C001",           // REFERENCE to customer â€” for direct lookup
  "amount": -45.67,                // negative = debit, positive = credit
  "merchant": "Whole Foods Market",
  "merchant_category": "grocery",
  "location": {
    "city": "McLean",
    "state": "VA",
    "country": "US",
    "lat": 38.9339,
    "lon": -77.1773
  },
  "timestamp": "2026-02-12T14:23:11Z",
  "status": "approved",
  "risk_score": 0.08,
  "channel": "card_present"
}
```

*Transactions are always separate â€” never embedded. A high-volume customer could have millions of transactions. MongoDB enforces a 16MB document size limit. Embedding transactions would eventually hit that ceiling and crash writes for active customers. Separate collection removes that ceiling entirely and lets transactions scale to any volume.*

*I include both account_id and customer_id on every transaction document. This looks like duplication but it's intentional â€” it allows direct customer-to-transactions queries without going through accounts, which is the most common fraud detection access pattern.*

**Collection 4 â€” customer_risk_profiles:**

```javascript
{
  "_id": "C001",
  "customer_id": "C001",
  "computed_at": "2026-02-12T14:00:00Z",
  "avg_transaction_amount_30d": 67.43,
  "transaction_count_30d": 47,
  "unique_merchants_30d": 23,
  "usual_locations": ["McLean VA", "Washington DC", "New York NY"],
  "usual_hours": [8, 9, 10, 12, 13, 18, 19, 20],
  "max_single_transaction_30d": 1200.00,
  "foreign_transaction_rate": 0.02,
  "ml_features": {
    "velocity_score": 0.12,
    "location_anomaly_score": 0.05,
    "amount_anomaly_score": 0.08,
    "overall_risk_score": 0.09
  }
}
```

*This fourth collection is read-heavy during real-time fraud processing â€” the Flink pipeline reads it for every transaction to get behavioral context. Keeping it separate from the core customer document means fraud pipeline reads don't compete with customer profile updates, and a batch job can refresh it every hour without touching customer data.*

**Indexes:**

```javascript
// customers collection
db.customers.createIndex({ "email": 1 }, { unique: true })
db.customers.createIndex({ "tier": 1 })

// accounts collection
db.accounts.createIndex({ "customer_id": 1 })
db.accounts.createIndex({ "status": 1 })

// transactions collection â€” compound indexes are critical
db.transactions.createIndex({ "account_id": 1, "timestamp": -1 })
db.transactions.createIndex({ "customer_id": 1, "timestamp": -1 })
db.transactions.createIndex({ "status": 1, "timestamp": -1 })
db.transactions.createIndex({ "risk_score": -1 })

// customer_risk_profiles
db.customer_risk_profiles.createIndex({ "customer_id": 1 }, { unique: true })
```

*Compound indexes on account_id plus timestamp and customer_id plus timestamp support the two most common query patterns â€” recent transactions for an account and recent transactions for a customer â€” in a single index scan with no in-memory sort.*

**Efficient Queries:**

```javascript
// 1. Load full customer profile â€” one document, one read
db.customers.findOne({ _id: "C001" })

// 2. Get customer with accounts â€” $lookup join
db.customers.aggregate([
  { $match: { _id: "C001" } },
  { $lookup: {
      from: "accounts",
      localField: "account_ids",
      foreignField: "_id",
      as: "accounts"
    }
  }
])

// 3. Recent transactions â€” compound index makes this fast
db.transactions.find(
  { customer_id: "C001" }
).sort({ timestamp: -1 }).limit(20)

// 4. Fraud detection query â€” get risk profile in one read
db.customer_risk_profiles.findOne({ customer_id: "C001" })

// 5. High risk transactions today â€” index on risk_score + timestamp
db.transactions.find({
  risk_score: { $gt: 0.80 },
  timestamp: {
    $gte: new Date("2026-02-12T00:00:00Z"),
    $lt:  new Date("2026-02-13T00:00:00Z")
  }
}).sort({ risk_score: -1 })

// 6. Schema validation â€” enforce data integrity
db.createCollection("transactions", {
  validator: {
    $jsonSchema: {
      bsonType: "object",
      required: ["account_id", "customer_id", "amount", "timestamp", "status"],
      properties: {
        amount: {
          bsonType: "double",
          description: "must be a number"
        },
        status: {
          enum: ["approved", "declined", "flagged", "pending"],
          description: "must be valid status"
        },
        risk_score: {
          bsonType: "double",
          minimum: 0,
          maximum: 1,
          description: "must be between 0 and 1"
        }
      }
    }
  }
})
```

*Schema validation gives us the flexibility of MongoDB with the data integrity guarantees a financial institution requires. Any document that violates these rules is rejected at write time â€” before it ever touches the database."*

---

# Document Design Diagrams

```
EMBED VS REFERENCE DECISION TREE
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                       â•‘
â•‘  For every piece of data ask:                                         â•‘
â•‘                                                                       â•‘
â•‘  Is the data bounded/small?                                           â•‘
â•‘         â”‚                                                             â•‘
â•‘        YESâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º NO                 â•‘
â•‘         â”‚                                          â”‚                 â•‘
â•‘         â–¼                                          â–¼                 â•‘
â•‘  Always accessed with parent?              Could it grow forever?    â•‘
â•‘         â”‚                                          â”‚                 â•‘
â•‘        YESâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º NO          YESâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º NO      â•‘
â•‘         â”‚                     â”‚            â”‚                  â”‚      â•‘
â•‘         â–¼                     â–¼            â–¼                  â–¼      â•‘
â•‘      EMBED                REFERENCE    REFERENCE           Either    â•‘
â•‘                                                                       â•‘
â•‘  Examples:                                                            â•‘
â•‘  Addresses     â†’ EMBED    (small, always needed)                     â•‘
â•‘  Accounts      â†’ REFERENCE (changes often, independent updates)      â•‘
â•‘  Transactions  â†’ REFERENCE (unbounded, would hit 16MB limit)         â•‘
â•‘  Risk features â†’ SEPARATE  (different access pattern)                â•‘
â•‘                                                                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


FOUR COLLECTION ARCHITECTURE
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                       â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â•‘
â•‘  â”‚  customers                                                  â”‚     â•‘
â•‘  â”‚  _id, name, email, addresses[ ], account_ids[ ]            â”‚     â•‘
â•‘  â”‚                        â”‚                  â”‚                â”‚     â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â•‘
â•‘                           â”‚                  â”‚                       â•‘
â•‘              references   â”‚                  â”‚  references           â•‘
â•‘                           â–¼                  â–¼                       â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â•‘
â•‘  â”‚  accounts        â”‚           â”‚  transactions              â”‚       â•‘
â•‘  â”‚  _id             â”‚           â”‚  _id                       â”‚       â•‘
â•‘  â”‚  customer_id â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â–ºcustomer_id               â”‚       â•‘
â•‘  â”‚  type            â”‚           â”‚  account_id â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”   â•‘
â•‘  â”‚  balance         â”‚           â”‚  amount                    â”‚  â”‚   â•‘
â•‘  â”‚  status          â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€account_id                â”‚  â”‚   â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚  timestamp                 â”‚  â”‚   â•‘
â•‘                                 â”‚  risk_score                â”‚  â”‚   â•‘
â•‘                                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â•‘
â•‘                                                                  â”‚   â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â•‘
â•‘  â”‚  customer_risk_profiles                                  â”‚â—„â”€â”€â”˜   â•‘
â•‘  â”‚  customer_id                                             â”‚       â•‘
â•‘  â”‚  ml_features{ }                                         â”‚       â•‘
â•‘  â”‚  behavioral_stats{ }                                    â”‚       â•‘
â•‘  â”‚  computed_at                                            â”‚       â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â•‘
â•‘                                                                       â•‘
â•‘  READ PATTERNS:                                                       â•‘
â•‘  Fraud pipeline â”€â”€â–º customer_risk_profiles (< 10ms lookup)           â•‘
â•‘  Customer portal â”€â”€â–º customers + accounts ($lookup)                  â•‘
â•‘  Transaction history â”€â”€â–º transactions (compound index scan)          â•‘
â•‘  Compliance â”€â”€â–º transactions (date range query)                      â•‘
â•‘                                                                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


COMPOUND INDEX PERFORMANCE
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                       â•‘
â•‘  Query: Recent transactions for customer C001                        â•‘
â•‘                                                                       â•‘
â•‘  WITHOUT compound index:                                             â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                               â•‘
â•‘  Step 1: Use customer_id index â†’ find 50,000 docs for C001          â•‘
â•‘  Step 2: Load all 50,000 into memory                                 â•‘
â•‘  Step 3: Sort by timestamp in memory â€” EXPENSIVE âŒ                  â•‘
â•‘  Step 4: Return top 20                                               â•‘
â•‘  Time: potentially seconds at scale                                  â•‘
â•‘                                                                       â•‘
â•‘  WITH compound index { customer_id: 1, timestamp: -1 }:             â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€             â•‘
â•‘  Step 1: Index already sorted by customer_id THEN timestamp         â•‘
â•‘  Step 2: Jump directly to C001 entries                              â•‘
â•‘  Step 3: Read top 20 in timestamp order â€” already sorted âœ…          â•‘
â•‘  Step 4: Done                                                        â•‘
â•‘  Time: milliseconds regardless of collection size âœ…                 â•‘
â•‘                                                                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


16MB DOCUMENT LIMIT â€” WHY TRANSACTIONS MUST BE SEPARATE
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                       â•‘
â•‘  Customer C001 â€” Premium customer since 2018                         â•‘
â•‘                                                                       â•‘
â•‘  Year 1:  ~500 transactions  Ã— 500 bytes = 250KB  âœ…                 â•‘
â•‘  Year 2: ~1000 transactions  Ã— 500 bytes = 500KB  âœ…                 â•‘
â•‘  Year 3: ~1500 transactions  Ã— 500 bytes = 750KB  âœ…                 â•‘
â•‘  Year 5: ~2500 transactions  Ã— 500 bytes = 1.25MB âœ…                 â•‘
â•‘  Year 8: ~4000 transactions  Ã— 500 bytes = 2MB    âœ…                 â•‘
â•‘  Year 10:~5000 transactions  Ã— 500 bytes = 2.5MB  âœ…                 â•‘
â•‘                                                                       â•‘
â•‘  High-volume customer â€” 20 transactions/day:                         â•‘
â•‘  Year 1:  7,300 transactions Ã— 500 bytes = 3.65MB âœ…                 â•‘
â•‘  Year 2: 14,600 transactions Ã— 500 bytes = 7.3MB  âš ï¸                â•‘
â•‘  Year 3: 21,900 transactions Ã— 500 bytes = 10.9MB âš ï¸                â•‘
â•‘  Year 4: 29,200 transactions Ã— 500 bytes = 14.6MB âš ï¸                â•‘
â•‘  Year 4.5:32,850 transactionsÃ— 500 bytes = 16.4MB âŒ WRITE FAILS    â•‘
â•‘                                                                       â•‘
â•‘  Separate collection = NO LIMIT âœ…                                   â•‘
â•‘                                                                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```



