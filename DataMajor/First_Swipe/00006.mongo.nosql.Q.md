
# Mock Interview â€” MongoDB & NoSQL

Same rules â€” answer like you're in the room. Model answer and diagrams after each response.

---

## Question 1 â€” Warm Up

**"Can you explain what NoSQL is, why it was created, and how MongoDB specifically differs from a traditional relational database like PostgreSQL or Oracle?"**

# Feedback First

---

## What You Nailed âœ…

**"Big companies got flooded with huge, messy, fast-changing data"** â€” perfect origin story. Concise and accurate.

**Three scaling problems identified** â€” rigid schemas, slow scaling, expensive at scale. All correct.

**Document vs row distinction** â€” cleanly explained. "Each one can have different fields" captures the core flexibility perfectly.

**Schema flexibility tradeoff** â€” correctly identified that relational requires upfront planning while MongoDB allows change. Shows maturity.

**"Many places use both"** â€” this is the senior engineer answer. Knowing that the real world uses polyglot persistence rather than picking one winner signals production experience.

**Best use cases** â€” correctly mapped relational to transactions and accuracy, MongoDB to speed and flexibility.

---

## What to Tighten Up ğŸ”§

**Missing the three V's of big data context** â€” giving the origin story more technical framing elevates it:

*"The NoSQL movement emerged around 2009-2010 driven by the three V's â€” Volume, Velocity, and Variety. Volume because datasets grew from gigabytes to petabytes. Velocity because data needed to be written and read in milliseconds not seconds. Variety because data stopped fitting neatly into rows and columns."*

**Missing BSON** â€” MongoDB specifically uses BSON not plain JSON. One sentence matters:

*"MongoDB stores data as BSON â€” Binary JSON â€” which extends JSON with additional data types like dates, integers, and binary data, and is optimized for fast serialization and deserialization."*

**Missing the join problem specifically** â€” this is the core technical reason NoSQL was needed:

*"The fundamental problem with relational databases at scale was joins. A query joining five tables with billions of rows each requires the database to correlate records across massive datasets â€” it becomes catastrophically slow. MongoDB solves this by embedding related data inside a single document, eliminating the join entirely."*

**Missing horizontal vs vertical scaling distinction** â€” your answer said "harder to add servers" but the technical framing is more precise:

*"Relational databases scale vertically â€” you buy a bigger, more expensive single server. MongoDB scales horizontally through sharding â€” you add more commodity servers and MongoDB distributes data across them automatically. At Capital One scale, horizontal scaling is the only economically viable option."*

---

# Model Answer

---

*"NoSQL stands for Not Only SQL â€” it's a family of database technologies that emerged around 2009 to 2010 to solve problems that relational databases couldn't handle at internet scale.*

**Why NoSQL was created:**

*The trigger was the three V's of big data â€” Volume, Velocity, and Variety. Volume because companies like Google, Amazon, and Facebook were dealing with petabytes of data, far beyond what a single relational database server could hold. Velocity because modern applications need reads and writes in milliseconds â€” a relational database doing complex joins across billion-row tables simply cannot deliver that. Variety because data stopped fitting neatly into rows and columns â€” user profiles, social posts, product catalogs, IoT sensor readings all have irregular, nested, variable structures that a fixed schema handles poorly.*

*Relational databases had three specific architectural limitations at this scale. First, rigid schemas â€” changing a table structure on a billion-row table requires a migration that can lock the table for hours. Second, vertical scaling â€” relational databases scale by buying bigger, more expensive single servers, which has a hard physical and economic ceiling. Third, the join problem â€” reconstructing a customer profile from five normalized tables with billions of rows each requires correlating massive datasets, which becomes catastrophically slow.*

*NoSQL solved all three â€” flexible schemas that change without migrations, horizontal scaling by adding commodity servers, and embedding related data together to eliminate joins.*

**How MongoDB specifically differs from PostgreSQL or Oracle:**

*MongoDB is a document database. Instead of storing data in rows and columns it stores self-contained documents in BSON format â€” Binary JSON â€” which extends standard JSON with additional data types optimized for fast serialization.*

*The fundamental difference is the data model. In PostgreSQL a customer record is spread across multiple normalized tables â€” a customers table, an addresses table, an accounts table, a transactions table â€” and you reconstruct the full customer picture with a multi-table join. In MongoDB that same customer is a single document containing all their information nested together. One read operation retrieves everything. No joins.*

*Schema is the second major difference. PostgreSQL requires you to define every column upfront. Adding a new field means an ALTER TABLE statement that can be expensive at scale. MongoDB has no enforced schema by default â€” you can add new fields to documents at any time without touching existing documents. Capital One would add schema validation rules on top to maintain data quality while keeping the flexibility.*

*Scaling is the third difference. PostgreSQL scales vertically â€” you buy a bigger server. MongoDB scales horizontally through sharding â€” you add more servers and MongoDB automatically distributes your data across them using a shard key. When Capital One's customer database grows from 50 million to 100 million customers, you add shards rather than buying a more expensive machine.*

*The honest answer for a bank like Capital One is that both have a role. Core financial transactions â€” debits, credits, transfers â€” live in relational databases because ACID compliance and complex reporting are non-negotiable there. Customer profiles, fraud case management, enrichment stores for ML models â€” those live in MongoDB because the data is naturally document-shaped and flexibility and read speed matter more than relational integrity."*

---

# Diagrams

```
WHY NOSQL WAS CREATED â€” THE THREE V'S
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                       â•‘
â•‘   VOLUME              VELOCITY             VARIETY                   â•‘
â•‘   â”€â”€â”€â”€â”€â”€              â”€â”€â”€â”€â”€â”€â”€â”€             â”€â”€â”€â”€â”€â”€â”€                   â•‘
â•‘   Gigabytes           Seconds              Rows & Columns            â•‘
â•‘      â”‚                   â”‚                     â”‚                     â•‘
â•‘      â”‚ grew to           â”‚ needed to be        â”‚ became              â•‘
â•‘      â–¼                   â–¼                     â–¼                     â•‘
â•‘   Petabytes           Milliseconds         Nested JSON               â•‘
â•‘                                            Arrays                    â•‘
â•‘                                            Variable fields           â•‘
â•‘                                            Unstructured text         â•‘
â•‘                                                                       â•‘
â•‘   Relational databases could not handle all three simultaneously     â•‘
â•‘   NoSQL was built specifically for this combination                  â•‘
â•‘                                                                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


RELATIONAL VS MONGODB â€” DATA MODEL
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                       â•‘
â•‘  RELATIONAL (PostgreSQL)          MONGODB                            â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”€â”€â”€â”€â”€â”€â”€                            â•‘
â•‘                                                                       â•‘
â•‘  customers table:                 customers collection:              â•‘
â•‘  â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”           {                                  â•‘
â•‘  â”‚ id â”‚ name  â”‚ email â”‚             "_id": "C001",                   â•‘
â•‘  â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤             "name": "Alice Johnson",         â•‘
â•‘  â”‚C001â”‚ Alice â”‚a@e.comâ”‚             "email": "a@e.com",              â•‘
â•‘  â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜             "address": {                     â•‘
â•‘                                       "city": "McLean",              â•‘
â•‘  addresses table:                     "state": "VA"                  â•‘
â•‘  â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”            },                               â•‘
â•‘  â”‚ id â”‚  city  â”‚ state â”‚            "accounts": [                    â•‘
â•‘  â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤              {"type": "checking",           â•‘
â•‘  â”‚C001â”‚ McLean â”‚  VA   â”‚               "balance": 5420.00},          â•‘
â•‘  â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜              {"type": "savings",            â•‘
â•‘                                        "balance": 28750.00}          â•‘
â•‘  accounts table:                    ],                               â•‘
â•‘  â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         "risk_score": 0.12,             â•‘
â•‘  â”‚ id â”‚   type   â”‚ balance â”‚         "is_premium": true              â•‘
â•‘  â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤       }                                 â•‘
â•‘  â”‚C001â”‚ checking â”‚ 5420.00 â”‚                                         â•‘
â•‘  â”‚C001â”‚ savings  â”‚28750.00 â”‚       ONE document                      â•‘
â•‘  â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       ONE read                          â•‘
â•‘                                    NO joins                          â•‘
â•‘  THREE tables                                                        â•‘
â•‘  ONE join query                                                      â•‘
â•‘  Gets slower as tables grow                                          â•‘
â•‘                                                                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


SCALING â€” VERTICAL VS HORIZONTAL
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                       â•‘
â•‘  RELATIONAL â€” VERTICAL SCALING         MONGODB â€” HORIZONTAL SCALING  â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â•‘
â•‘                                                                       â•‘
â•‘        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”   â•‘
â•‘        â”‚ BIGGEST â”‚                    â”‚Shard 1â”‚â”‚Shard 2â”‚â”‚Shard 3â”‚   â•‘
â•‘        â”‚ SERVER  â”‚                    â”‚C001-  â”‚â”‚C334K- â”‚â”‚C667K- â”‚   â•‘
â•‘        â”‚ MONEY   â”‚                    â”‚C333K  â”‚â”‚C666K  â”‚â”‚C999K  â”‚   â•‘
â•‘        â”‚ CAN BUY â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”˜   â•‘
â•‘        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â–²        â–²        â–²      â•‘
â•‘             â–²                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â•‘
â•‘             â”‚                                       â”‚               â•‘
â•‘        Hit ceiling                          mongos router           â•‘
â•‘        Buy even bigger                      directs queries         â•‘
â•‘        server ğŸ’¸                            to right shard          â•‘
â•‘                                                                      â•‘
â•‘        Hard physical limit                 Add shards = add scale   â•‘
â•‘        Expensive                           Commodity servers        â•‘
â•‘        Single point of failure             Fault tolerant           â•‘
â•‘                                                                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


TERM MAPPING â€” RELATIONAL TO MONGODB
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                       â•‘
â•‘   RELATIONAL          MONGODB              NOTES                     â•‘
â•‘   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”€â”€â”€â”€â”€â”€â”€              â”€â”€â”€â”€â”€                     â•‘
â•‘   Database      â•â•â–º   Database             Same concept              â•‘
â•‘   Table         â•â•â–º   Collection           No fixed schema           â•‘
â•‘   Row           â•â•â–º   Document             JSON/BSON format          â•‘
â•‘   Column        â•â•â–º   Field                Varies per document       â•‘
â•‘   Primary Key   â•â•â–º   _id                  Auto-generated if needed  â•‘
â•‘   Foreign Key   â•â•â–º   Reference/Embed      Design choice             â•‘
â•‘   JOIN          â•â•â–º   $lookup / Embed      Embed = no join needed    â•‘
â•‘   INDEX         â•â•â–º   Index                Same concept              â•‘
â•‘   VIEW          â•â•â–º   View                 Same concept              â•‘
â•‘   SQL           â•â•â–º   MQL                  MongoDB Query Language    â•‘
â•‘   ACID Txn      â•â•â–º   Multi-doc Txn        Added in MongoDB 4.0      â•‘
â•‘                                                                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


WHEN TO USE WHICH AT CAPITAL ONE
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                       â•‘
â•‘   USE RELATIONAL (PostgreSQL/Oracle) WHEN:                           â•‘
â•‘   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                  â•‘
â•‘   âœ… Core financial transactions â€” debits, credits, transfers        â•‘
â•‘   âœ… Regulatory reporting requiring complex joins                    â•‘
â•‘   âœ… ACID compliance across multiple entities is non-negotiable      â•‘
â•‘   âœ… Data is highly structured and consistent                        â•‘
â•‘                                                                       â•‘
â•‘   USE MONGODB WHEN:                                                   â•‘
â•‘   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                  â•‘
â•‘   âœ… Customer 360 profiles â€” nested, variable attributes             â•‘
â•‘   âœ… Fraud case management â€” each case has different evidence        â•‘
â•‘   âœ… ML feature store â€” hundreds of behavioral features per customer â•‘
â•‘   âœ… Transaction enrichment â€” fast lookup during real-time pipeline  â•‘
â•‘   âœ… Product catalogs â€” different fields per product type            â•‘
â•‘                                                                       â•‘
â•‘   CAPITAL ONE LIKELY USES BOTH â€” polyglot persistence                â•‘
â•‘   Right database for the right job                                   â•‘
â•‘                                                                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---
---
---

## Question 2 â€” Stepping Up

**"Walk me through MongoDB's architecture â€” replica sets, sharding, and the WiredTiger storage engine. How do these components work together to give you both high availability and horizontal scale?"**

# Feedback First

---

## What You Nailed âœ…

**Replica set primary/secondary model** â€” correctly explained. One primary handles writes, secondaries replicate, automatic election on failure. Accurate and complete.

**"Automatic election"** â€” mentioning this specifically shows you understand that MongoDB's high availability is self-healing, not manual.

**Sharding components** â€” correctly identified all three pieces â€” shards, config servers, and mongos routers. Most candidates miss the config server entirely.

**"Each shard holds part of the data"** â€” correct. And giving an example like user ID or region shows you understand the shard key concept.

**WiredTiger as the storage layer** â€” correctly positioned it as the underlying engine and correctly identified compression, caching, and crash recovery.

**"Each shard is itself a replica set"** â€” your closing summary implied this correctly. This is the key insight that combines both concepts.

**The file cabinet analogy** â€” simple and memorable for WiredTiger.

---

## What to Tighten Up ğŸ”§

**Missing the shard key design importance.** This is the most critical MongoDB architecture decision and deserves more attention:

*"The shard key is the most important design decision in a sharded MongoDB deployment. A bad shard key â€” one with low cardinality or that causes hotspots â€” can make sharding worse than not sharding at all. For Capital One's customer collection, customer_id is a good shard key because it has high cardinality, distributes writes evenly, and queries are almost always scoped to a single customer."*

**Missing ranged vs hashed sharding.** Two sentences would complete the picture:

*"MongoDB supports two sharding strategies. Range-based sharding groups similar shard key values together â€” good for range queries but can cause hotspots if values are sequential. Hashed sharding distributes documents by hashing the shard key â€” guarantees even distribution but makes range queries less efficient."*

**Missing the odd-number rule for replica sets.** Critical detail:

*"Replica sets always run an odd number of members â€” typically three or five â€” because elections require a majority vote to elect a new primary. With two members, if one goes down you can't reach majority and the set becomes read-only. Three members means one failure still leaves two members to reach majority and elect a new primary."*

**Missing WiredTiger document-level locking.** This is its key performance feature:

*"WiredTiger's most important performance characteristic is document-level concurrency control â€” multiple operations on different documents can run simultaneously without blocking each other. The older MMAPv1 engine used collection-level locking, meaning one write blocked all other writes to the entire collection. WiredTiger eliminated that bottleneck."*

---

# Model Answer

---

*"MongoDB's architecture has three layers that work together to deliver both high availability and horizontal scale â€” replica sets for reliability, sharding for scale, and WiredTiger for storage efficiency.*

**Replica Sets:**

*A replica set is a group of MongoDB instances â€” always an odd number, typically three â€” that all hold identical copies of the same data. The odd number is deliberate â€” elections require a majority vote to choose a new primary, and an even number could result in a tie.*

*One member is the Primary â€” it receives all write operations and propagates changes to the other members through an operation log called the oplog. The other members are Secondaries â€” they continuously replicate from the Primary's oplog and stay current within milliseconds.*

*If the Primary goes down â€” hardware failure, network partition, planned maintenance â€” the Secondaries detect the absence of heartbeats and automatically hold an election. Within typically 10 to 30 seconds a new Primary is elected and the cluster resumes accepting writes. No human intervention required. This is MongoDB's high availability story.*

*Secondaries can also serve read operations, which is useful for distributing read-heavy workloads. Capital One might route fraud model feature lookups to secondaries to avoid adding read pressure to the Primary that's handling all transaction writes.*

**Sharding:**

*Sharding is MongoDB's horizontal scaling mechanism. When a single replica set can no longer handle your data volume or write throughput, you shard â€” splitting the data across multiple replica sets called shards.*

*The architecture has three components. The shards themselves â€” each one is a full replica set holding a subset of the total data. The config servers â€” a small replica set that stores metadata about which shard holds which data ranges. And the mongos routers â€” lightweight processes that sit in front of everything and direct incoming queries to the correct shard based on the shard key.*

*The shard key is the most critical design decision in a MongoDB deployment. It determines how data is distributed across shards. A good shard key has high cardinality â€” many distinct values â€” and distributes writes evenly to avoid hotspots. For Capital One's customer collection, customer_id is an ideal shard key. For a transactions collection, a compound key of customer_id plus date distributes data evenly while supporting the most common query patterns.*

*MongoDB supports two sharding strategies. Range-based sharding groups documents with similar shard key values on the same shard â€” good for range queries like "all transactions between date A and date B" but risks hotspots if values are sequential or clustered. Hashed sharding applies a hash function to the shard key and distributes documents based on the hash â€” guarantees even distribution but sacrifices range query efficiency.*

**WiredTiger Storage Engine:**

*WiredTiger is the storage engine that runs underneath everything â€” it handles how data is physically written to and read from disk on each node.*

*Its most important performance characteristic is document-level concurrency control. Multiple write operations on different documents execute simultaneously without blocking each other. The older MMAPv1 engine used collection-level locking â€” one write blocked all other writes to the entire collection. At Capital One's transaction volume that would be catastrophic. WiredTiger eliminated that bottleneck entirely.*

*WiredTiger also applies compression by default â€” Snappy compression for data files and Zlib for the journal. This typically reduces storage footprint by 60 to 80 percent compared to uncompressed storage, which at Capital One scale translates to significant infrastructure cost savings.*

*Finally WiredTiger uses checkpointing â€” writing a consistent snapshot of all data to disk every 60 seconds by default. Combined with a write-ahead journal that logs every operation, WiredTiger can recover to a consistent state after a crash with minimal data loss.*

**How They Work Together:**

*Each shard is itself a full replica set â€” so you get both horizontal scale and high availability simultaneously. A three-shard cluster with three-member replica sets means nine MongoDB instances total, any one of which can fail without impact. WiredTiger running on every node ensures each instance is reading and writing efficiently with compression and document-level concurrency.*

*For Capital One â€” a customer_profiles collection sharded by customer_id across three shards, each shard a three-member replica set, WiredTiger compressed and checkpointed â€” gives you a system that handles hundreds of millions of customer documents, survives any individual server failure, and scales by simply adding shards as the customer base grows."*

---

# Architecture Diagrams

```
REPLICA SET â€” HIGH AVAILABILITY
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                       â•‘
â•‘                    REPLICA SET (3 members)                           â•‘
â•‘                                                                       â•‘
â•‘         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â•‘
â•‘         â”‚                                         â”‚                  â•‘
â•‘         â–¼                                         â–¼                  â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    oplog    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚                  â•‘
â•‘  â”‚  PRIMARY    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ SECONDARY 1 â”‚      â”‚                  â•‘
â•‘  â”‚             â”‚             â”‚             â”‚      â”‚                  â•‘
â•‘  â”‚ All writes  â”‚    oplog    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”‚                  â•‘
â•‘  â”‚ All reads   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ SECONDARY 2 â”‚      â”‚                  â•‘
â•‘  â”‚ (default)   â”‚             â”‚             â”‚      â”‚                  â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜      â”‚                  â•‘
â•‘         â”‚                          â”‚              â”‚                  â•‘
â•‘         â”‚ heartbeat every 2s       â”‚ heartbeat    â”‚                  â•‘
â•‘         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚                  â•‘
â•‘                                                   â”‚                  â•‘
â•‘  PRIMARY GOES DOWN:                               â”‚                  â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                â”‚                  â•‘
â•‘  Secondaries detect missing heartbeat             â”‚                  â•‘
â•‘         â”‚                                         â”‚                  â•‘
â•‘         â–¼                                         â”‚                  â•‘
â•‘  Election triggered â€” majority vote needed        â”‚                  â•‘
â•‘  2 remaining members = majority of 3 âœ…           â”‚                  â•‘
â•‘         â”‚                                         â”‚                  â•‘
â•‘         â–¼                                         â”‚                  â•‘
â•‘  Secondary 1 elected new PRIMARY                  â”‚                  â•‘
â•‘  Recovery: 10-30 seconds                          â”‚                  â•‘
â•‘  Zero data loss (oplog replicated) âœ…             â”‚                  â•‘
â•‘                                                   â”‚                  â•‘
â•‘  WHY ODD NUMBERS:                                 â”‚                  â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                 â”‚                  â•‘
â•‘  2 members: 1 fails â†’ 1 remaining                 â”‚                  â•‘
â•‘             cannot reach majority â†’ READ ONLY âŒ  â”‚                  â•‘
â•‘  3 members: 1 fails â†’ 2 remaining                 â”‚                  â•‘
â•‘             majority reached â†’ NEW PRIMARY âœ…     â”‚                  â•‘
â•‘  5 members: 2 fail  â†’ 3 remaining                 â”‚                  â•‘
â•‘             majority reached â†’ NEW PRIMARY âœ…     â”‚                  â•‘
â•‘                                                   â”‚                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                                                    â”‚
                                                    â”‚
SHARDING â€” HORIZONTAL SCALE                        â”‚
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                   â”‚                  â•‘
â•‘   APPLICATION                                     â”‚                  â•‘
â•‘        â”‚                                          â”‚                  â•‘
â•‘        â–¼                                          â”‚                  â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚                  â•‘
â•‘  â”‚   mongos    â”‚  â—„â”€â”€ Query router                â”‚                  â•‘
â•‘  â”‚   ROUTER    â”‚      Directs to right shard      â”‚                  â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                  â”‚                  â•‘
â•‘         â”‚                                         â”‚                  â•‘
â•‘         â”‚ consults                                â”‚                  â•‘
â•‘         â–¼                                         â”‚                  â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚                  â•‘
â•‘  â”‚   CONFIG    â”‚  â—„â”€â”€ Stores chunk metadata       â”‚                  â•‘
â•‘  â”‚   SERVERS   â”‚      "C001-C333K lives on Shard1"â”‚                  â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                  â”‚                  â•‘
â•‘         â”‚                                         â”‚                  â•‘
â•‘         â”‚ routes to                               â”‚                  â•‘
â•‘         â–¼                                         â”‚                  â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚                  â•‘
â•‘  â”‚              SHARDS                      â”‚     â”‚                  â•‘
â•‘  â”‚                                          â”‚     â”‚                  â•‘
â•‘  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚     â”‚                  â•‘
â•‘  â”‚  â”‚ SHARD 1  â”‚ â”‚ SHARD 2  â”‚ â”‚ SHARD 3  â”‚ â”‚     â”‚                  â•‘
â•‘  â”‚  â”‚(Replica  â”‚ â”‚(Replica  â”‚ â”‚(Replica  â”‚ â”‚     â”‚                  â•‘
â•‘  â”‚  â”‚  Set)    â”‚ â”‚  Set)    â”‚ â”‚  Set)    â”‚ â”‚     â”‚                  â•‘
â•‘  â”‚  â”‚          â”‚ â”‚          â”‚ â”‚          â”‚ â”‚     â”‚                  â•‘
â•‘  â”‚  â”‚ C001 to  â”‚ â”‚ C334K to â”‚ â”‚ C667K to â”‚ â”‚     â”‚                  â•‘
â•‘  â”‚  â”‚ C333K    â”‚ â”‚ C666K    â”‚ â”‚ C999K    â”‚ â”‚     â”‚                  â•‘
â•‘  â”‚  â”‚          â”‚ â”‚          â”‚ â”‚          â”‚ â”‚     â”‚                  â•‘
â•‘  â”‚  â”‚ P+S1+S2  â”‚ â”‚ P+S1+S2  â”‚ â”‚ P+S1+S2  â”‚ â”‚     â”‚                  â•‘
â•‘  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚     â”‚                  â•‘
â•‘  â”‚  Each shard = full replica set âœ…        â”‚     â”‚                  â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚                  â•‘
â•‘                                                   â”‚                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                                                    â”‚
WIREDTIGER â€” STORAGE ENGINE                        â”‚
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                   â”‚                  â•‘
â•‘  EVERY NODE IN EVERY SHARD RUNS WIREDTIGER        â”‚                  â•‘
â•‘                                                   â”‚                  â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚                  â•‘
â•‘  â”‚              WiredTiger                    â”‚   â”‚                  â•‘
â•‘  â”‚                                            â”‚   â”‚                  â•‘
â•‘  â”‚  Document-level     Compression            â”‚   â”‚                  â•‘
â•‘  â”‚  concurrency   â”€â”€â–º  Snappy: data files     â”‚   â”‚                  â•‘
â•‘  â”‚                     Zlib:   journal        â”‚   â”‚                  â•‘
â•‘  â”‚  Many writes on     60-80% size reduction  â”‚   â”‚                  â•‘
â•‘  â”‚  different docs     at Capital One scale   â”‚   â”‚                  â•‘
â•‘  â”‚  simultaneously âœ…  = massive cost saving  â”‚   â”‚                  â•‘
â•‘  â”‚                                            â”‚   â”‚                  â•‘
â•‘  â”‚  Checkpointing â”€â”€â–º  Snapshot every 60s     â”‚   â”‚                  â•‘
â•‘  â”‚                     + write-ahead journal  â”‚   â”‚                  â•‘
â•‘  â”‚                     = crash recovery âœ…    â”‚   â”‚                  â•‘
â•‘  â”‚                                            â”‚   â”‚                  â•‘
â•‘  â”‚  Cache â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º  Frequently accessed    â”‚   â”‚                  â•‘
â•‘  â”‚                     docs stay in RAM       â”‚   â”‚                  â•‘
â•‘  â”‚                     = fast reads âœ…        â”‚   â”‚                  â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚                  â•‘
â•‘                                                   â”‚                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


SHARD KEY DESIGN â€” CRITICAL DECISION
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                       â•‘
â•‘  BAD SHARD KEY              GOOD SHARD KEY                           â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€               â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                          â•‘
â•‘                                                                       â•‘
â•‘  created_date               customer_id                              â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                              â•‘
â•‘  All new writes go to       Writes distributed                       â•‘
â•‘  "today" shard              evenly across all shards                 â•‘
â•‘                                                                       â•‘
â•‘  Shard 1: JAN â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   Shard 1: C001-C333K â–ˆâ–ˆâ–ˆâ–ˆ                 â•‘
â•‘  Shard 2: FEB â–ˆâ–ˆâ–ˆâ–ˆ         Shard 2: C334K-C666K â–ˆâ–ˆâ–ˆâ–ˆ                â•‘
â•‘  Shard 3: TODAY â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  Shard 3: C667K-C999K â–ˆâ–ˆâ–ˆâ–ˆ                â•‘
â•‘                                                                       â•‘
â•‘  HOTSPOT âŒ                 EVEN DISTRIBUTION âœ…                     â•‘
â•‘                                                                       â•‘
â•‘  RANGE SHARDING             HASHED SHARDING                          â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€             â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                         â•‘
â•‘  Good for: range queries    Good for: write distribution             â•‘
â•‘  Risk: hotspots             Risk: range queries hit all shards       â•‘
â•‘                                                                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


THE COMPLETE PICTURE â€” ALL THREE LAYERS
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                       â•‘
â•‘  APPLICATION REQUEST: "Get customer C001 profile"                    â•‘
â•‘         â”‚                                                             â•‘
â•‘         â–¼                                                             â•‘
â•‘  mongos router checks config server                                  â•‘
â•‘  "C001 lives on Shard 1" â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â•‘
â•‘                                                         â”‚            â•‘
â•‘         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â•‘
â•‘         â–¼                                                             â•‘
â•‘  SHARD 1 (Replica Set)                                               â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â•‘
â•‘  â”‚  PRIMARY                                        â”‚                 â•‘
â•‘  â”‚  WiredTiger checks cache â†’ found in RAM âœ…      â”‚                 â•‘
â•‘  â”‚  Returns document in < 10ms                     â”‚                 â•‘
â•‘  â”‚                                                 â”‚                 â•‘
â•‘  â”‚  Meanwhile oplog replicating to:                â”‚                 â•‘
â•‘  â”‚  Secondary 1 âœ…  Secondary 2 âœ…                 â”‚                 â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â•‘
â•‘         â”‚                                                             â•‘
â•‘         â–¼                                                             â•‘
â•‘  Customer document returned to application                           â•‘
â•‘  Total time: < 10ms âœ…                                               â•‘
â•‘  High availability: 2 replicas ready to take over âœ…                 â•‘
â•‘  Horizontal scale: add Shard 4 when needed âœ…                        â•‘
â•‘                                                                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---
---
---
## Question 3 â€” Getting Serious

**"How would you model a Capital One customer's data in MongoDB? Walk me through your document design decisions â€” what you embed, what you reference, and why. Then show me how you would query it efficiently."**

