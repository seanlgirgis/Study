
### Course Overview
- **Instructor**: Hadrien
- **Type**: Conceptual (no coding)
- **Goal**:
  - Non-developers → talk confidently with data engineering teams
  - Future developers → build strong conceptual foundation
- **Fictional company example**: Spotflix (music streaming service)
- **Main data flow stages**:
  - Collect / Ingest
  - Store (raw)
  - Prepare / Clean
  - Exploit (explore, visualize, dashboard)
  - Experiment / Model (analytics, ML, predictions)

### Chapter 1 – What is Data Engineering?

**Role of Data Engineers**
- Responsible for **first part** of data workflow:
  - Ingest data from many sources
  - Store it correctly
  - Deliver clean, accessible, optimized data to analysts / scientists
- Enable data scientists, analysts, ML engineers
- Build & maintain **data pipelines**

**Data Engineers vs Data Scientists**
- **Data Engineer** (software-oriented):
  - Ingest + store + pipeline building
  - Optimize databases for analysis
  - Languages: Python/Java (software), SQL (structure)
- **Data Scientist** (analytics-oriented):
  - Prepare, explore, visualize, model
  - Query databases
  - Languages: Python/R (analytics), SQL (querying)
- Engineers lay foundation → scientists build insights on top

**Data Pipeline Concept**
- Analogy: "Data is the new oil" → crude → refined products → distribution
- **Purpose**:
  - Automate Extract → Transform → Combine → Validate → Load
  - Reduce manual work + errors
  - Keep data fresh, accurate, relevant
- **ETL** (most common pattern):
  - **E**xtract
  - **T**ransform
  - **L**oad
- Not all pipelines are ETL (some load raw / direct to apps)

**Spotflix Pipeline Examples**
- Sources → Data Lake: mobile app, desktop app, website, HR system
- Then pipelines to organized databases: artists, albums, tracks, playlists, customers, employees
- Further pipelines: album covers, department tables (sales, engineering), regional splits, clean tracks after validation

### Chapter 2 – Data Storage

**Three Types of Data**

- **Structured** (~20% of data)
  - Fixed columns + types (like spreadsheet)
  - Easy to search / relate
  - Stored in **relational databases** (RDBMS)
  - Queried with **SQL**
  - Example: Spotflix employee table (ID, name, role, team, full_time boolean, office)

- **Semi-structured**
  - Flexible but still organized
  - Allows varying fields (e.g. different number of favorite artists)
  - Common formats: **JSON**, **XML**, **YAML**
  - Stored in **NoSQL** databases
  - Example: User favorite artists JSON

- **Unstructured** (most common)
  - No fixed model (text, audio, images, video)
  - Hard to search without ML/AI
  - Stored in **data lakes**
  - Spotflix examples: lyrics, songs, album covers, music videos

**SQL – The Core Language**
- Used for **Relational Database Management Systems** (RDBMS)
- Advantages: handle many records, group/filter/aggregate easily, readable (English-like)
- **Data Engineers**: CREATE / UPDATE tables, maintain structure
- **Data Scientists**: SELECT / query for analysis
- Example commands shown: CREATE TABLE, SELECT ... WHERE LIKE '%data%'

**Database Schema**
- Multiple related tables linked by keys (e.g. artist_id, album_id, song_id)
- Enables relational joins (artists ↔ albums ↔ songs ↔ playlists)

**Data Lake vs Data Warehouse vs Database**

- **Data Lake**
  - Stores **raw**, **all types** (structured/semi/unstructured)
  - Very large (petabytes)
  - No enforced schema → cheap but hard to analyze
  - Needs **data catalog** (metadata, lineage, ownership) to avoid "data swamp"
  - Used for: big data exploration, ML, real-time analytics

- **Data Warehouse**
  - Stores **clean, structured, specific-purpose** data
  - Optimized for analytics / reporting / aggregations
  - Smaller than lakes, more expensive to maintain
  - Used by: analysts for dashboards, BI

- **Database** (general term)
  - Any organized collection
  - Data warehouse is one type of database

### Chapter 3 – Processing, Scheduling, Computing

**Data Processing**
- Convert raw → meaningful information
- Why?
  - Remove useless data
  - Compress
  - Change format (e.g. WAV → .ogg at Spotflix)
  - Extract metadata
  - Enforce schema
  - Clean / validate
  - Automate repetitive prep → free scientists for insight work
- Engineer tasks: cleaning, views, indexing, performance optimization

**Scheduling**
- Glue that runs tasks in correct order + handles dependencies
- Types:
  - **Manual** (immediate, human-triggered)
  - **Time-based** (every day 6 AM)
  - **Sensor/condition-based** (only if new data arrived)
- **Batch** vs **Stream**
  - Batch: grouped, periodic, cheaper (night jobs)
  - Stream: real-time, record-by-record (sign-ups, online listening)
- Tools: Apache Airflow, Luigi

**Parallel Computing**
- Split big task → many small subtasks → run on multiple machines
- Benefits: faster, lower memory per machine
- Costs: data movement, coordination overhead
- Spotflix example: convert many songs to .ogg in parallel

**Cloud Computing**
- Rent servers instead of owning
- Benefits:
  - Pay only for what you use
  - Scale easily
  - Global distribution → low latency
  - Built-in replication / disaster recovery
- Main providers: AWS, Azure, Google Cloud
- Spotflix uses **AWS**: S3 (storage), EC2 (compute), RDS (databases)
- **Multicloud**: possible but complex (vendor lock-in, compatibility, governance)

### Final Summary – What You Learned
- Define data engineering & its importance
- Data engineer vs data scientist
- Data pipelines & ETL
- Structured / semi-structured / unstructured data
- SQL & relational databases
- Data lake vs warehouse
- Processing, scheduling, batch vs stream
- Parallel & cloud computing

