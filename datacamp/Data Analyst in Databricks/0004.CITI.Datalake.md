### Citi's Data Lake Setup â€“ What I Found from a Deep Dive (2026 Update)

Citigroup (Citi) is a massive global bank, so they don't rely on **one single "data lake"** like smaller companies do. Instead, they have a **hybrid, evolving setup** that's been modernized over the years. Here's the clear picture based on recent sources (job postings, partnerships, articles from 2024â€“2026):

#### 1. **The Core / Legacy Data Lake: "Virtual Enterprise Data Lake" (Hadoop-based)**
   - This is Citi's long-standing central data lake, often called the **Virtual Enterprise Data Lake**.
   - Built primarily on **Hadoop** (HDFS, Hive, YARN, MapReduce).
   - It's a classic "enterprise data lake" that ingests huge amounts of structured + unstructured data from across the bank.
   - Purpose: Reduces duplicate data, lowers costs, makes data actionable fast for fraud, compliance, cybersecurity, marketing, etc.
   - Still actively used and mentioned in 2026 job postings (e.g., Big Data Engineer roles require Hadoop skills).

#### 2. **Modern Evolution: Moving to Cloud + Data Fabric (Not a Pure Traditional Lake Anymore)**
   - Citi has shifted toward a **data fabric architecture** (confirmed in 2025â€“2026 articles).
     - This is a smart layer on top that unifies fragmented data across the bank without moving everything.
     - Uses metadata + AI for governance, real-time analytics, compliance, and fraud detection.
   - They're building newer data lakes by pulling from legacy systems into cloud storage (e.g., for client dashboards in Citi Commercial Bank).

#### 3. **Key Cloud Tools & Platforms Citi Actually Uses Today**
   - **Snowflake** â†’ Strong official partnership (since 2021, still active). Used heavily in securities services/post-trade for secure data sharing and analytics. Many roles mention Snowflake pipelines.
   - **Databricks** â†’ Increasingly used, especially for big data + AI/ML workloads. Multiple 2026 job postings require Databricks experience (e.g., "Cloud - AWS, Databricks" or listed alongside Hadoop/Snowflake). Citi also collaborates with Databricks on industry AI governance initiatives.
   - **AWS** â†’ Frequently mentioned for cloud data lakes (S3 likely as the storage backbone for modern parts).
   - **Hadoop still hangs on** â†’ For legacy big data processing, but they're clearly modernizing.

#### Quick Summary Table for Easy Comparison

| Layer/Use Case          | Main Technology                          | Notes / Why They Use It                          |
|-------------------------|------------------------------------------|--------------------------------------------------|
| Legacy Core Lake        | Hadoop (Virtual Enterprise Data Lake)   | Reliable, battle-tested for massive scale       |
| Cloud Warehouse/Sharing | Snowflake                               | Secure sharing, post-trade, fast analytics      |
| Lakehouse / AI / Modern | Databricks + AWS (likely Delta Lake on S3) | Appears in many new jobs; great for ML + streaming |
| Overall Architecture    | Data Fabric (metadata + AI governance)  | Unifies everything, fixes past fragmentation issues |

**Bottom line** â†’ Citi started with a classic **Hadoop data lake** (Virtual Enterprise Data Lake), but today it's a **multi-tool, cloud-hybrid data fabric** with heavy use of **Snowflake** and growing adoption of **Databricks** (which means they likely have Delta Lake tables in parts of their lakehouse). No single public announcement says "we run everything on Databricks" or "pure Delta Lakehouse," because big banks like Citi use best-of-breed tools in different areas.

If you're asking because of the Databricks course â€” yes, Citi is definitely using Databricks in real roles right now (check their job postings!). They're in the middle of the same lakehouse journey most big banks are on.

Want me to dig into a specific part (e.g., more on Databricks at Citi) or check a particular source? Just say! ðŸš€